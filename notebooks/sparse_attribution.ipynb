{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import load_tinymodel, load_tinydataset, load_saes\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 548.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to tokenize 0 tokens\n",
      "Number of datapoints w/ 129 tokens: 9473\n",
      "Total Tokens: 1.222017M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/notebooks/notebook_utils.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "llm = load_tinymodel()\n",
    "dataset = load_tinydataset(batch_size=32, max_seq_length=128, num_datapoints=10000)\n",
    "all_saes = load_saes(k=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def load_module_names(llm):\n",
    "#     module_names = []\n",
    "#     for name, module in llm.named_modules():\n",
    "#         module_names.append(name)\n",
    "#     return module_names\n",
    "# module_names = load_module_names(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Features Memory: 3.17 MB\n",
      "Virtual Weights Memory: 161.17 MB\n",
      "Attribution Memory: 20629.88 MB\n",
      "Total Memory: 20.31 GB\n"
     ]
    }
   ],
   "source": [
    "def calculate_gpu_memory(b, i, j, dtype=torch.float32):\n",
    "    bytes_per_element = torch.tensor([], dtype=dtype).element_size()\n",
    "    \n",
    "    input_features_memory = b * i * bytes_per_element\n",
    "    virtual_weights_memory = i * j * bytes_per_element\n",
    "    attribution_memory = b * i * j * bytes_per_element\n",
    "    \n",
    "    total_memory = input_features_memory + virtual_weights_memory + attribution_memory\n",
    "    \n",
    "    return {\n",
    "        \"input_features_memory\": input_features_memory,\n",
    "        \"virtual_weights_memory\": virtual_weights_memory,\n",
    "        \"attribution_memory\": attribution_memory,\n",
    "        \"total_memory\": total_memory,\n",
    "        \"total_memory_gb\": total_memory / (1024**3)\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "b = 1*128\n",
    "i, j =  6500, 6500  # Your dimensions\n",
    "memory_info = calculate_gpu_memory(b, i, j)\n",
    "\n",
    "print(f\"Input Features Memory: {memory_info['input_features_memory'] / (1024**2):.2f} MB\")\n",
    "print(f\"Virtual Weights Memory: {memory_info['virtual_weights_memory'] / (1024**2):.2f} MB\")\n",
    "print(f\"Attribution Memory: {memory_info['attribution_memory'] / (1024**2):.2f} MB\")\n",
    "print(f\"Total Memory: {memory_info['total_memory_gb']:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/297 [00:03<19:37,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 4.6019062995910645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/297 [00:08<19:53,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.013808727264404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/297 [00:12<19:36,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.252461910247803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/297 [00:15<18:44,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.421160697937012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/297 [00:19<18:20,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.536966323852539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/297 [00:22<17:58,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.624728202819824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/297 [00:26<17:44,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.6972174644470215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/297 [00:29<17:23,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.754840850830078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/297 [00:33<17:32,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.80457878112793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/297 [00:37<17:53,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.848028182983398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/297 [00:41<17:40,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.885636329650879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/297 [00:45<17:44,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.918002128601074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/297 [00:48<17:29,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.946206092834473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 14/297 [00:52<17:14,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.971977710723877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/297 [00:55<17:18,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 5.995954990386963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/297 [00:59<17:07,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.017444133758545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/297 [01:03<16:58,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.037295818328857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/297 [01:06<17:06,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.055354118347168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 19/297 [01:10<16:50,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.072602272033691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/297 [01:13<16:27,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.090076446533203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/297 [01:17<16:24,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.107024192810059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/297 [01:21<16:23,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.121205806732178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 23/297 [01:24<16:29,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.135374546051025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/297 [01:28<16:26,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.148035526275635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/297 [01:31<16:23,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.159493923187256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 26/297 [01:35<16:18,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.170994758605957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 27/297 [01:39<16:11,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.1819586753845215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/297 [01:42<16:01,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.192153453826904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 29/297 [01:46<15:50,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.2013397216796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 30/297 [01:49<15:57,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.210585594177246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 31/297 [01:53<15:56,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.219674110412598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 32/297 [01:56<15:46,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.229183673858643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 33/297 [02:00<15:45,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.23756217956543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 34/297 [02:04<15:43,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.245084285736084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 35/297 [02:07<15:32,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.251889228820801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/297 [02:11<15:34,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.259177207946777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 37/297 [02:14<15:18,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.266119956970215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 38/297 [02:18<15:44,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.2727861404418945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 39/297 [02:22<15:47,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.278965950012207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/297 [02:25<15:31,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.285182476043701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 41/297 [02:29<15:33,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.290903091430664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 42/297 [02:33<15:29,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.296571254730225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 43/297 [02:36<15:28,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.3022613525390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/297 [02:40<15:21,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.306918621063232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 45/297 [02:44<15:25,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.312348365783691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 46/297 [02:47<15:26,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.317654609680176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 47/297 [02:51<15:17,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.322332382202148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 48/297 [02:55<15:13,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.327293395996094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 49/297 [02:59<15:31,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.331892490386963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 50/297 [03:02<15:16,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.336668968200684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 51/297 [03:06<15:13,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.34138822555542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 52/297 [03:10<15:00,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.345682144165039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 53/297 [03:13<14:49,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.349698543548584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 54/297 [03:17<14:47,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.353908538818359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 55/297 [03:20<14:29,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.357517242431641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 56/297 [03:24<14:34,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.361351490020752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 57/297 [03:28<14:31,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.365324974060059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 58/297 [03:31<14:23,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.368999481201172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 59/297 [03:35<14:13,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.372711181640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 60/297 [03:38<14:08,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.37627649307251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 61/297 [03:42<14:08,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.379827976226807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 62/297 [03:46<14:13,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.3829545974731445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 63/297 [03:49<13:53,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.386387348175049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 64/297 [03:53<13:55,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.389688491821289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 65/297 [03:56<13:48,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.393080234527588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 66/297 [04:00<13:41,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.396552562713623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 67/297 [04:03<13:33,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.3995585441589355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 68/297 [04:07<13:34,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.40273380279541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 69/297 [04:10<13:25,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.405427932739258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 70/297 [04:14<13:30,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.4081854820251465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 71/297 [04:18<13:27,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.411192893981934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 72/297 [04:21<13:25,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.413645267486572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 73/297 [04:25<13:23,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.416391372680664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 74/297 [04:28<13:13,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.418892860412598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 75/297 [04:32<13:06,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.4214630126953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 76/297 [04:35<13:13,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.4239935874938965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 77/297 [04:39<13:35,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.426420211791992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 78/297 [04:43<13:20,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.428950309753418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 79/297 [04:47<13:12,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.431337833404541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 80/297 [04:50<12:52,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.43356466293335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 81/297 [04:54<12:50,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.436020851135254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 82/297 [04:57<12:44,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.438394546508789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 83/297 [05:01<12:45,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.4409565925598145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 84/297 [05:05<13:21,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.4430084228515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 85/297 [05:09<13:50,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.445380687713623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 86/297 [05:13<14:11,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.447420597076416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 87/297 [05:18<14:19,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.449489116668701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 88/297 [05:22<14:32,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.451460361480713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 89/297 [05:26<14:27,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.453432083129883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 90/297 [05:30<13:49,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.4554290771484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 91/297 [05:33<13:10,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.457250595092773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 92/297 [05:37<12:52,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.459177017211914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 93/297 [05:40<12:36,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.461000919342041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 94/297 [05:44<12:37,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.462841987609863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 95/297 [05:48<12:27,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.464639663696289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 96/297 [05:52<12:20,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.466277122497559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 97/297 [05:55<12:10,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.46816349029541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 98/297 [05:59<12:07,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.470128536224365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 99/297 [06:02<12:06,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.471836566925049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 100/297 [06:06<12:10,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.473741054534912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 101/297 [06:10<12:12,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.4753618240356445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 102/297 [06:14<12:11,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.477178573608398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 103/297 [06:17<11:55,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.478771209716797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 104/297 [06:21<11:51,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.480522155761719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 105/297 [06:25<11:48,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.482283115386963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 106/297 [06:28<11:44,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.483983516693115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 107/297 [06:32<11:36,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.4856414794921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 108/297 [06:36<11:39,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.487205982208252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 109/297 [06:39<11:30,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.48890495300293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 110/297 [06:43<11:34,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.490471363067627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 111/297 [06:47<11:40,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.491923809051514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 112/297 [06:51<11:34,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.49326753616333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 113/297 [06:55<11:27,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.494739532470703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 114/297 [06:58<11:27,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.496330738067627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 115/297 [07:02<11:19,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.497791767120361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 116/297 [07:06<11:14,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.499151706695557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 117/297 [07:09<11:04,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.500448703765869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 118/297 [07:13<10:54,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.501816272735596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 119/297 [07:17<10:59,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.503171920776367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 120/297 [07:20<10:56,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.504556179046631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 121/297 [07:24<10:46,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.505866527557373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 122/297 [07:28<10:54,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.507228851318359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 123/297 [07:32<10:54,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.508492469787598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 124/297 [07:36<10:49,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.509705543518066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 125/297 [07:39<10:35,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.511117935180664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 126/297 [07:43<10:29,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.512387275695801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 127/297 [07:46<10:29,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.513679027557373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 128/297 [07:50<10:20,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.515023708343506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 129/297 [07:54<10:14,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5162506103515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 130/297 [07:57<10:02,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.517513275146484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 131/297 [08:01<10:05,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.518761157989502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 132/297 [08:04<09:50,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.51996374130249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 133/297 [08:08<09:43,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.521084785461426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 134/297 [08:12<09:49,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5222487449646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 135/297 [08:15<09:46,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.523406505584717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 136/297 [08:19<09:45,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.524528503417969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 137/297 [08:23<09:42,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.525569915771484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 138/297 [08:26<09:39,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.526641845703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 139/297 [08:30<09:33,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.527734279632568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 140/297 [08:34<09:34,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.528910160064697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 141/297 [08:37<09:36,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.530008316040039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 142/297 [08:41<09:18,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.531063079833984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 143/297 [08:44<09:13,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.53220796585083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 144/297 [08:48<09:12,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.533309459686279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 145/297 [08:52<09:07,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.534363746643066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 146/297 [08:55<08:58,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.53545618057251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 147/297 [08:59<08:56,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.53645658493042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 148/297 [09:02<09:00,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.537423610687256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 149/297 [09:06<08:58,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.538393974304199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 150/297 [09:10<08:56,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.539439678192139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 151/297 [09:13<08:55,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.540396213531494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 152/297 [09:17<09:07,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.541382789611816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 153/297 [09:21<08:59,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.542479991912842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 154/297 [09:25<08:53,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.543610095977783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 155/297 [09:28<08:43,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.544554233551025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 156/297 [09:32<08:39,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.54537296295166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 157/297 [09:36<08:31,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.546234130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 158/297 [09:39<08:35,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.547173023223877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 159/297 [09:43<08:33,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.548068523406982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 160/297 [09:47<08:24,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.549022674560547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 161/297 [09:50<08:08,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5499138832092285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 162/297 [09:54<08:06,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.550824165344238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 163/297 [09:58<08:06,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.551697731018066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 164/297 [10:01<08:01,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.552578449249268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 165/297 [10:05<07:57,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.553519248962402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 166/297 [10:08<07:51,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.554316520690918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 167/297 [10:12<07:44,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.555163860321045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 168/297 [10:15<07:39,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.555984020233154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 169/297 [10:19<07:40,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.556931018829346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 170/297 [10:23<07:31,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.55778694152832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 171/297 [10:26<07:34,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.55864143371582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 172/297 [10:30<07:31,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.559535980224609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 173/297 [10:33<07:28,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.560349464416504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 174/297 [10:37<07:27,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.561136245727539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 175/297 [10:41<07:25,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.561947822570801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 176/297 [10:44<07:20,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.562758922576904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 177/297 [10:48<07:20,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.563602447509766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 178/297 [10:52<07:19,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.564403533935547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 179/297 [10:55<07:09,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5652031898498535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 180/297 [10:59<07:04,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.565951347351074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 181/297 [11:03<06:59,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5667548179626465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 182/297 [11:06<06:56,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.567470073699951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 183/297 [11:10<06:51,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.568172931671143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 184/297 [11:14<06:49,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.568896770477295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 185/297 [11:17<06:42,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.569651126861572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 186/297 [11:21<06:35,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.570399284362793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 187/297 [11:24<06:33,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5711989402771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 188/297 [11:28<06:29,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.571893692016602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 189/297 [11:31<06:27,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.572530746459961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 190/297 [11:35<06:24,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.573238849639893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 191/297 [11:39<06:21,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.573971748352051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 192/297 [11:42<06:21,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.574687480926514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 193/297 [11:46<06:20,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5754313468933105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 194/297 [11:50<06:17,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.576186656951904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 195/297 [11:53<06:13,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.576908111572266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 196/297 [11:57<06:10,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.577602863311768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 197/297 [12:01<06:03,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.578331470489502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 198/297 [12:04<06:01,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.578949928283691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 199/297 [12:08<06:01,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.579595565795898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 200/297 [12:12<05:55,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.580244541168213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 201/297 [12:15<05:47,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.580898284912109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 202/297 [12:19<05:46,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.581531524658203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 203/297 [12:22<05:41,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.582156658172607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 204/297 [12:26<05:39,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.582777500152588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 205/297 [12:30<05:33,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.583491325378418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 206/297 [12:33<05:30,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.584157943725586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 207/297 [12:37<05:28,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.584805011749268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 208/297 [12:41<05:26,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.585461616516113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 209/297 [12:44<05:23,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.586156368255615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 210/297 [12:48<05:19,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5867695808410645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 211/297 [12:52<05:14,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.587451457977295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 212/297 [12:55<05:09,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.588086128234863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 213/297 [12:59<05:09,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.588723182678223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 214/297 [13:03<05:08,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.589366912841797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 215/297 [13:07<05:01,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.589947700500488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 216/297 [13:10<04:54,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.590611934661865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 217/297 [13:14<04:52,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.591202259063721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 218/297 [13:18<04:51,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.591790676116943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 219/297 [13:21<04:43,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.592392444610596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 220/297 [13:25<04:38,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5930023193359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 221/297 [13:28<04:35,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.593626976013184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 222/297 [13:32<04:33,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.594297409057617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 223/297 [13:36<04:33,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.594924449920654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 224/297 [13:39<04:29,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.595523357391357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 225/297 [13:43<04:28,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.59606409072876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 226/297 [13:47<04:23,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.596643447875977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 227/297 [13:51<04:19,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.5972089767456055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 228/297 [13:54<04:14,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.597804069519043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 229/297 [13:58<04:08,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.598364353179932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 230/297 [14:02<04:10,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.598906517028809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 231/297 [14:05<04:04,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.599515438079834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 232/297 [14:09<03:59,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.60009241104126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 233/297 [14:13<03:54,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.600650310516357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 234/297 [14:16<03:49,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.601309299468994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 235/297 [14:20<03:44,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.601834297180176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 236/297 [14:23<03:39,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.60231351852417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 237/297 [14:27<03:35,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.60280704498291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 238/297 [14:31<03:31,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.603311061859131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 239/297 [14:34<03:27,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.603893280029297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 240/297 [14:38<03:23,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.604425430297852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 241/297 [14:41<03:21,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.604897499084473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 242/297 [14:45<03:18,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.605400085449219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 243/297 [14:49<03:14,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.605947017669678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 244/297 [14:52<03:11,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.606469631195068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 245/297 [14:56<03:10,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.607003211975098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 246/297 [14:59<03:04,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.607460021972656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 247/297 [15:03<03:03,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.607953071594238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 248/297 [15:07<02:59,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.608480453491211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 249/297 [15:10<02:54,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.608996868133545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 250/297 [15:14<02:51,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.609491348266602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 251/297 [15:18<02:47,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.609989643096924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 252/297 [15:21<02:44,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.610555648803711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 253/297 [15:25<02:38,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.611053943634033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 254/297 [15:29<02:34,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.611571311950684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 255/297 [15:32<02:32,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.612060070037842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 256/297 [15:36<02:27,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.612536430358887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 257/297 [15:40<02:26,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.613034725189209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 258/297 [15:43<02:23,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.613509654998779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 259/297 [15:47<02:19,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.614010810852051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 260/297 [15:51<02:16,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.6144938468933105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 261/297 [15:54<02:11,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.615018844604492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 262/297 [15:58<02:07,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.615475654602051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 263/297 [16:02<02:03,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.6159348487854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 264/297 [16:05<01:59,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.616417407989502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 265/297 [16:09<01:57,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.616879940032959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 266/297 [16:13<01:54,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.617344856262207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 267/297 [16:16<01:49,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.617781639099121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 268/297 [16:20<01:45,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.618200778961182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 269/297 [16:23<01:42,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.618668556213379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 270/297 [16:27<01:38,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.619110107421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 271/297 [16:31<01:34,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.619598865509033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 272/297 [16:34<01:31,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.620059490203857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 273/297 [16:38<01:27,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.620479583740234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 274/297 [16:41<01:22,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.620945930480957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 275/297 [16:45<01:19,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.6214423179626465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 276/297 [16:49<01:15,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.621847629547119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 277/297 [16:52<01:12,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.622287750244141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 278/297 [16:56<01:09,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.6226806640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 279/297 [17:00<01:05,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.623119831085205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 280/297 [17:03<01:01,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.623559474945068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 281/297 [17:07<00:58,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.623980522155762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 282/297 [17:11<00:55,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.6244025230407715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 283/297 [17:14<00:51,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.62485933303833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 284/297 [17:18<00:47,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.625260829925537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 285/297 [17:22<00:43,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.625650882720947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 286/297 [17:25<00:40,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.6260833740234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 287/297 [17:29<00:36,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.626458168029785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 288/297 [17:32<00:32,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.626872539520264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 289/297 [17:36<00:29,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.627291202545166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 290/297 [17:40<00:25,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.627765655517578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 291/297 [17:44<00:22,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.628192901611328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 292/297 [17:47<00:18,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.628569602966309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 293/297 [17:51<00:14,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.629022121429443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 294/297 [17:55<00:11,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.629427909851074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 295/297 [17:59<00:07,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.629866123199463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 296/297 [18:02<00:03,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.630290985107422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [18:04<00:00,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 6.630242347717285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, einsum\n",
    "\n",
    "def update_running_average_with_sum(current_avg, new_sum, current_count, new_count):\n",
    "    \"\"\"\n",
    "    Update the running average with a new sum and count.\n",
    "    \n",
    "    :param current_avg: Current running average\n",
    "    :param new_sum: Sum of new values to include in the average\n",
    "    :param current_count: Number of values in the current average\n",
    "    :param new_count: Number of new values\n",
    "    :return: New running average, Updated total count\n",
    "    \"\"\"\n",
    "    if current_count == 0:\n",
    "        return new_sum / new_count, new_count\n",
    "    \n",
    "    total_count = current_count + new_count\n",
    "    updated_sum = current_avg * current_count + new_sum\n",
    "    updated_avg = updated_sum / total_count\n",
    "    return updated_avg, total_count\n",
    "\n",
    "target_sae_names = ['torso_1_mlp_out_transcoder', 'torso_1_res_final']\n",
    "saes = [all_saes[name].to(device) for name in target_sae_names]\n",
    "num_input_features = saes[0].encoder.weight.shape[0]\n",
    "num_output_features = saes[1].encoder.weight.shape[0]\n",
    "feature_by_feature_attribution = torch.zeros(num_input_features, num_output_features).to(device)\n",
    "running_total_for_each_feature = torch.zeros(num_output_features).to(device)\n",
    "\n",
    "resid_mid = llm.torso[1].res_mlp\n",
    "resid_final = llm.torso[1].res_final\n",
    "mlp_out = llm.torso[1].mlp\n",
    "# for batch_ind, batch in enumerate(dataset):\n",
    "# add tqdm to enumerate correctly\n",
    "from tqdm import tqdm\n",
    "entropy_across_batches = []\n",
    "with torch.no_grad():\n",
    "    for batch_ind, batch in enumerate(tqdm(dataset)):\n",
    "        batch = batch.to(device)\n",
    "        with llm.trace(batch) as tracr:\n",
    "            act_res_mid = resid_mid.output.save()\n",
    "            act_res_final = resid_final.output.save()\n",
    "            act_mlp_out = mlp_out.output.save()\n",
    "        # Now we want to run through the saes\n",
    "        transcoder = saes[0].to(device)\n",
    "        sae_final = saes[1].to(device)\n",
    "        # mlp_out_hat = transcoder(act_res_mid)\n",
    "\n",
    "        # sae_final_features_hat = sae_final.encode(mlp_out_hat+act_res_mid)\n",
    "        # maybe figure out a way to fold in the decoder bias?\n",
    "        tr_dec = transcoder.decoder.weight\n",
    "        #TODO: we removed the last weight to help w/ knowing .T and shape. \n",
    "        final_enc = sae_final.encoder.weight\n",
    "        virtual_weights = tr_dec.T @ final_enc.T\n",
    "\n",
    "        act_res_mid = act_res_mid.to(device)\n",
    "        act_res_mid = rearrange(act_res_mid, 'b s d_model -> (b s) d_model')\n",
    "        input_features, input_acts, input_indices = transcoder.encode(act_res_mid, return_topk=True)\n",
    "        # input_features = rearrange(input_features, 'b s f -> (b s) f')\n",
    "        # input_acts = rearrange(input_acts, 'b s f-> (b s) f')\n",
    "        # input_indices = rearrange(input_indices, 'b s f -> (b s) f')\n",
    "        mlp_out_hat = transcoder.decoder(input_features)\n",
    "\n",
    "        output_features, output_acts, output_indices = sae_final.encode(mlp_out_hat + act_res_mid, return_topk=True)\n",
    "\n",
    "        # Gradient equals the weights\n",
    "        # attribution = torch.einsum('bi,ij->bij', input_features, virtual_weights)\n",
    "        # features_set_yet = torch.zeros(num_output_features, dtype=torch.bool)\n",
    "\n",
    "        for current_output_feature in range(num_output_features):\n",
    "            # Get the batch indices where the output feature is non-zero\n",
    "            nz_batch_indices = (output_indices==current_output_feature).sum(-1).nonzero()[:, 0]\n",
    "            output_virtual_weights = virtual_weights[:, current_output_feature]\n",
    "\n",
    "            # Index into the virtual weights & input indices ie find the inputs that activated the output feature\n",
    "            nz_input_ind = input_indices[nz_batch_indices]\n",
    "            batched_virtual_weights = output_virtual_weights[nz_input_ind].to(device)\n",
    "            nz_input_acts = input_acts[nz_batch_indices]\n",
    "\n",
    "            # Calculate the attribution ie act*gradient\n",
    "            current_output_attribution = nz_input_acts * batched_virtual_weights \n",
    "\n",
    "            # Set the feature by feature attribution (average w/ existing attributions)    \n",
    "            averaged_current_output_attribution = current_output_attribution.mean(dim=0)\n",
    "            \n",
    "            # The new count is the number of non-zero batch indices for this feature\n",
    "            new_count = len(nz_batch_indices)\n",
    "\n",
    "            # Update the feature_by_feature_attribution using the running average with sum\n",
    "            feature_by_feature_attribution[nz_input_ind, current_output_feature], running_total_for_each_feature[current_output_feature] = update_running_average_with_sum(\n",
    "                current_avg = feature_by_feature_attribution[nz_input_ind, current_output_feature],\n",
    "                new_sum = current_output_attribution,\n",
    "                current_count = running_total_for_each_feature[current_output_feature],\n",
    "                new_count = new_count\n",
    "            )\n",
    "        if(batch_ind %1 == 0):\n",
    "            # Now we want to divide feature_by_feature_attribution by each of the times it activated\n",
    "            alive_output_features = running_total_for_each_feature != 0\n",
    "\n",
    "            averaged_feature_by_feature_attribution = feature_by_feature_attribution[:, alive_output_features] / running_total_for_each_feature[alive_output_features].unsqueeze(0)\n",
    "            # Now we want to convert to a prob-dist and calculate entropy on it, ignoring dead features\n",
    "            normed_feature_by_feature_attribution = averaged_feature_by_feature_attribution / averaged_feature_by_feature_attribution.abs().sum(dim=0)\n",
    "\n",
    "            logged = normed_feature_by_feature_attribution.abs().log()\n",
    "            logged[logged.isinf()] = 0\n",
    "            entropy = -(normed_feature_by_feature_attribution.abs() * logged).sum(dim=0)\n",
    "            entropy_across_batches.append(entropy.mean().item())\n",
    "            print(f\"Entropy: {entropy.mean().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot entropy_across_batches\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(entropy_across_batches)\n",
    "plt.xlabel(\"Number of Tokens\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "# Set x indicies to be in increments of 10 to make it easier to read\n",
    "# Each tick is 128*32 tokens\n",
    "# Measure as M of tokens\n",
    "n_ticks = 50\n",
    "plt.xticks(range(0, len(entropy_across_batches), n_ticks), [f\"{i*128*32/1e6:.2f}M\" for i in range(0, len(entropy_across_batches), n_ticks)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.206844329833984]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_across_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2069, device='cuda:0')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want to divide feature_by_feature_attribution by each of the times it activated\n",
    "alive_output_features = running_total_for_each_feature != 0\n",
    "\n",
    "averaged_feature_by_feature_attribution = feature_by_feature_attribution[:, alive_output_features] / running_total_for_each_feature[alive_output_features].unsqueeze(0)\n",
    "# Now we want to convert to a prob-dist and calculate entropy on it, ignoring dead features\n",
    "normed_feature_by_feature_attribution = averaged_feature_by_feature_attribution / averaged_feature_by_feature_attribution.abs().sum(dim=0)\n",
    "\n",
    "logged = normed_feature_by_feature_attribution.abs().log()\n",
    "logged[logged.isinf()] = 0\n",
    "entropy = -(normed_feature_by_feature_attribution.abs() * logged).sum(dim=0)\n",
    "entropy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:0'),\n",
       " tensor(False, device='cuda:0'),\n",
       " tensor(False, device='cuda:0'),\n",
       " tensor(True, device='cuda:0'),\n",
       " tensor(True, device='cuda:0'),\n",
       " tensor(False, device='cuda:0'),\n",
       " tensor(True, device='cuda:0'))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(running_total_for_each_feature[alive_output_features] == 0).any(), running_total_for_each_feature[alive_output_features].isnan().any(), feature_by_feature_attribution.isnan().any(), normed_feature_by_feature_attribution.isnan().any(), entropy.isnan().any(), averaged_feature_by_feature_attribution.isnan().any(), (averaged_feature_by_feature_attribution == 0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged[logged.isnan()], logged.isnan().nonzero()\n",
    "normed_feature_by_feature_attribution.abs()[0, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    -inf,     -inf,     -inf,  ..., -10.5742,     -inf,     -inf],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in range(10):\n",
    "    assert (normed_feature_by_feature_attribution[:, N] == feature_by_feature_attribution[:, N] / running_total_for_each_feature[N]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False, False,  ..., False, False, False], device='cuda:0'),\n",
       " torch.Size([4128, 30]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_acts[output_indices==0]\n",
    "input_acts[output_indices==0]\n",
    "(output_indices==0).sum(-1) != 0, input_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2369],\n",
       "        [3193],\n",
       "        [3194],\n",
       "        [3204],\n",
       "        [3207],\n",
       "        [3798]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((output_indices==0).sum(-1) != 0).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_output_feature = 0\n",
    "num_input_features = input_features.shape[-1]\n",
    "num_output_features = output_features.shape[-1]\n",
    "feature_by_feature_attribution = torch.zeros(num_input_features, num_output_features).to(device)\n",
    "# features_set_yet = torch.zeros(num_output_features, dtype=torch.bool)\n",
    "iteration = 1\n",
    "\n",
    "for current_output_feature in range(num_output_features):\n",
    "    # Get the batch indices where the output feature is non-zero\n",
    "    nz_batch_indices = (output_indices==current_output_feature).sum(-1).nonzero()[:, 0]\n",
    "    output_virtual_weights = virtual_weights[:, current_output_feature]\n",
    "\n",
    "    # Index into the virtual weights & input indices ie find the inputs that activated the output feature\n",
    "    nz_input_ind = input_indices[nz_batch_indices]\n",
    "    batched_virtual_weights = output_virtual_weights[nz_input_ind].to(device)\n",
    "    nz_input_acts = input_acts[nz_batch_indices]\n",
    "\n",
    "    # Calculate the attribution ie act*gradient\n",
    "    current_output_attribution = nz_input_acts * batched_virtual_weights \n",
    "\n",
    "    # Set the feature by feature attribution (average w/ existing attributions)    \n",
    "    averaged_current_output_attribution = current_output_attribution.mean(dim=0)\n",
    "    tmp_feature_list = torch.zeros(num_input_features).to(device)\n",
    "    # Assign the averaged attributions to the correct input features\n",
    "    # tmp_feature_list[nz_input_ind] = averaged_current_output_attribution\n",
    "\n",
    "    feature_by_feature_attribution[nz_input_ind, current_output_feature] += averaged_current_output_attribution\n",
    "\n",
    "# Normalize the attributions (by abs value cause negative gradients)\n",
    "# total_abs_value = current_output_attribution.abs().sum(dim=-1)\n",
    "# normed_current_output_attribution = current_output_attribution / total_abs_value[:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0'),\n",
       " tensor(0.7414, device='cuda:0'))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution.abs().sum(dim=-1), normed_current_output_attribution.mean(dim=0).abs().sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution.abs().mean(dim=0).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 30])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Normalize: \u001b[39;00m\n\u001b[1;32m      3\u001b[0m normed_current_output_attribution \u001b[38;5;241m=\u001b[39m current_output_attribution \u001b[38;5;241m/\u001b[39m total_abs_value[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m normed_current_output_attribution\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_abs_value = current_output_attribution.abs().sum(dim=-1)\n",
    "# Normalize: \n",
    "normed_current_output_attribution = current_output_attribution / total_abs_value[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6227e-02, -2.6679e-03, -2.5494e-02, -1.2283e-03,  1.7044e-01,\n",
       "         -4.9746e-02, -1.8890e-02, -6.3689e-02, -3.3854e-02,  1.7237e-01,\n",
       "         -6.0978e-03,  2.1763e-02, -4.3416e-02,  7.5457e-02,  2.9024e-02,\n",
       "         -6.1067e-03,  5.2058e-03, -3.8862e-02, -6.2616e-03, -1.0429e-02,\n",
       "         -2.1213e-02, -3.2377e-02, -2.1631e-02,  1.1801e-02, -4.8583e-02,\n",
       "          7.9568e-03,  3.5445e-03, -9.7144e-03, -1.8767e-02, -7.1831e-03],\n",
       "        [-1.3719e-02,  2.5239e-03,  4.5559e-01,  6.0995e-03,  1.5561e-01,\n",
       "         -4.0269e-02, -1.2523e-02, -4.5647e-02,  6.8993e-03, -1.0656e-02,\n",
       "         -5.3215e-02, -1.6520e-02, -9.7398e-03,  2.4028e-03, -1.1964e-02,\n",
       "         -5.8181e-03, -1.9840e-02, -1.1012e-03, -1.8136e-02,  2.4025e-03,\n",
       "          2.2144e-04,  1.3957e-02, -2.2930e-02,  9.7942e-03, -1.6925e-02,\n",
       "         -5.8936e-03, -6.2075e-03,  1.3838e-02, -1.9537e-02,  2.1156e-05],\n",
       "        [-9.3610e-02,  2.0581e-03,  2.8441e-03, -1.7609e-02,  3.2889e-01,\n",
       "          2.9626e-03, -5.8919e-03, -9.6776e-03,  1.6282e-02, -3.5212e-02,\n",
       "         -1.0118e-01,  1.1903e-02,  2.6110e-02, -4.1736e-02,  1.5991e-02,\n",
       "         -3.8399e-03, -5.5625e-03, -3.4391e-02, -4.4615e-02, -2.1330e-02,\n",
       "          2.6017e-03,  2.2486e-04, -3.8361e-02,  4.8169e-02,  3.6406e-02,\n",
       "          1.2068e-02, -1.4367e-02, -1.3132e-02, -2.5259e-03, -1.0446e-02],\n",
       "        [-8.1073e-03,  4.2762e-02, -5.2288e-02,  4.5075e-03,  3.3414e-01,\n",
       "          2.7188e-03, -1.4417e-02, -1.8804e-02,  1.2070e-01,  4.3481e-03,\n",
       "          4.6848e-05, -4.1434e-02, -3.2482e-02, -1.1042e-02, -1.0281e-02,\n",
       "          1.1483e-03, -3.4628e-02,  2.5828e-03, -2.0375e-02,  2.2612e-02,\n",
       "         -4.7735e-03,  3.2990e-04, -2.8831e-02, -3.4438e-02,  1.6669e-04,\n",
       "         -4.7174e-02, -1.0905e-02, -8.9945e-03, -7.7301e-02, -7.6553e-03],\n",
       "        [-5.0751e-03, -4.3663e-02,  3.6039e-03,  2.9102e-01,  6.3041e-03,\n",
       "         -1.4183e-02, -6.8183e-02,  6.1243e-03, -4.5275e-02, -2.7905e-03,\n",
       "         -1.1467e-02, -7.7277e-02,  5.9998e-03,  1.1346e-02,  7.9721e-04,\n",
       "         -3.7884e-02, -1.1661e-02, -2.0265e-02,  1.7895e-02, -5.9277e-02,\n",
       "         -1.9032e-02, -7.0333e-03,  1.2288e-02,  3.3335e-02, -2.6896e-02,\n",
       "         -1.2939e-02, -1.0968e-01,  6.8002e-03, -1.8959e-02, -1.2946e-02],\n",
       "        [ 3.2406e-03,  5.2416e-01, -2.5509e-03, -2.0306e-03, -7.5386e-03,\n",
       "          1.6643e-01,  1.2463e-02,  4.3980e-03, -1.0011e-02,  1.3485e-02,\n",
       "         -2.3036e-03, -1.9625e-03, -1.6080e-02,  8.4582e-04,  9.0141e-03,\n",
       "         -1.5201e-02, -3.6115e-03,  5.4018e-03, -1.2612e-02, -3.4631e-03,\n",
       "         -3.1816e-02, -2.7081e-03, -3.3674e-02,  1.9163e-02,  5.9009e-03,\n",
       "         -1.0380e-02, -6.0363e-02,  3.3278e-03, -1.5466e-02,  4.0239e-04]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2906, 0.4918, 0.3760, 0.3835, 0.3477, 0.5571], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution.norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4699, device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_output_attribution[0].abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_input_indices = torch.unique(input_indices)\n",
    "input_features[:, unique_input_indices].isnan().any()\n",
    "unique_output_indices = torch.unique(output_indices)\n",
    "\n",
    "# output_features.shape, unique_output_indices.shape\n",
    "# virtual_weights[unique_input_indices][:, unique_output_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6144, 6143]), tensor(6143, device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virtual_weights.shape, unique_output_indices.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 795.99 GiB. GPU 0 has a total capacity of 15.73 GiB of which 14.37 GiB is free. Process 2007258 has 1.35 GiB memory in use. Of the allocated memory 1.07 GiB is allocated by PyTorch, and 93.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m sparse_virtual_weights \u001b[38;5;241m=\u001b[39m virtual_weights[unique_input_indices][:, unique_output_indices]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Perform the sparse matrix multiplication\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m spar_attr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbi,ij->bij\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_input_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_virtual_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# # Create a tensor to hold the full attribution\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# full_attribution = torch.zeros(input_features.shape[0], input_features.shape[1], virtual_weights.shape[1], device=input_features.device)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# # Place the sparse attribution results in the correct positions in the full attribution tensor\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# full_attribution[:, unique_input_indices[:, None], unique_output_indices] = spar_attr\u001b[39;00m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/functional.py:386\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    388\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 795.99 GiB. GPU 0 has a total capacity of 15.73 GiB of which 14.37 GiB is free. Process 2007258 has 1.35 GiB memory in use. Of the allocated memory 1.07 GiB is allocated by PyTorch, and 93.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum\n",
    "\n",
    "\n",
    "def sparse_attribution(input_features, virtual_weights, input_indices, output_indices):\n",
    "    # Find unique input and output indices across the batch\n",
    "    unique_input_indices = torch.unique(input_indices)\n",
    "    unique_output_indices = torch.unique(output_indices)\n",
    "\n",
    "    # combine batch and sequence dimensions\n",
    "    input_features = rearrange(input_features, 'b s i -> (b s) i')\n",
    "\n",
    "    # Extract relevant slices of input_features and virtual_weights\n",
    "    sparse_input_features = input_features[:, unique_input_indices]\n",
    "    sparse_virtual_weights = virtual_weights[unique_input_indices][:, unique_output_indices]\n",
    "\n",
    "    # Perform the sparse matrix multiplication\n",
    "    sparse_attribution = torch.einsum('bi,ij->bij', sparse_input_features, sparse_virtual_weights)\n",
    "\n",
    "    # Create a tensor to hold the full attribution\n",
    "    full_attribution = torch.zeros(input_features.shape[0], input_features.shape[1], virtual_weights.shape[1], device=input_features.device)\n",
    "\n",
    "    # Place the sparse attribution results in the correct positions in the full attribution tensor\n",
    "    full_attribution[:, unique_input_indices[:, None], unique_output_indices] = sparse_attribution\n",
    "\n",
    "    return full_attribution\n",
    "\n",
    "# Usage\n",
    "# Assuming input_features, virtual_weights, input_indices, and output_indices are defined\n",
    "# attribution = sparse_attribution(input_features, virtual_weights, input_indices, output_indices)\n",
    "\n",
    "unique_input_indices = torch.unique(input_indices)\n",
    "unique_output_indices = torch.unique(output_indices)\n",
    "\n",
    "# Extract relevant slices of input_features and virtual_weights\n",
    "sparse_input_features = input_features[:, unique_input_indices]\n",
    "sparse_virtual_weights = virtual_weights[unique_input_indices][:, unique_output_indices]\n",
    "\n",
    "# Perform the sparse matrix multiplication\n",
    "spar_attr = torch.einsum('bi,ij->bij', sparse_input_features, sparse_virtual_weights)\n",
    "\n",
    "# # Create a tensor to hold the full attribution\n",
    "# full_attribution = torch.zeros(input_features.shape[0], input_features.shape[1], virtual_weights.shape[1], device=input_features.device)\n",
    "\n",
    "# # Place the sparse attribution results in the correct positions in the full attribution tensor\n",
    "# full_attribution[:, unique_input_indices[:, None], unique_output_indices] = spar_attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8256, 6144]), torch.Size([4292]), torch.Size([6030]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.shape, unique_input_indices.shape, unique_output_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8256, 4292]), torch.Size([4292, 6030]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_input_features.shape, sparse_virtual_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_features shape: torch.Size([64, 129, 6144])\n",
      "unique_input_indices shape: torch.Size([4292])\n",
      "Max value in unique_input_indices: 6142\n",
      "Min value in unique_input_indices: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"input_features shape:\", input_features.shape)\n",
    "unique_input_indices = torch.unique(input_indices)\n",
    "print(\"unique_input_indices shape:\", unique_input_indices.shape)\n",
    "print(\"Max value in unique_input_indices:\", unique_input_indices.max().item())\n",
    "print(\"Min value in unique_input_indices:\", unique_input_indices.min().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_input_indices = input_indices.unique()\n",
    "unique_output_indices = output_indices.unique()\n",
    "\n",
    "# # Extract relevant slices of input_features and virtual_weights\n",
    "sparse_input_features = input_features[:, unique_input_indices]\n",
    "sparse_virtual_weights = virtual_weights[unique_input_indices][:, unique_output_indices]\n",
    "# sparse_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4292,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq = input_indices.unique().cpu().numpy()\n",
    "uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minput_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "input_features.index([0,1], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 32\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m full_attribution\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Assuming input_features, virtual_weights, input_indices, and output_indices are defined\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# attribution = sparse_attribution(input_features, virtual_weights, input_indices, output_indices)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m unique_input_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m unique_output_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(output_indices)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Extract relevant slices of input_features and virtual_weights\u001b[39;00m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/_jit_internal.py:503\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/_jit_internal.py:503\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/functional.py:997\u001b[0m, in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 997\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/functional.py:911\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    903\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    905\u001b[0m         dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[1;32m    909\u001b[0m     )\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1160.81 GiB. GPU 0 has a total capacity of 15.73 GiB of which 13.95 GiB is free. Process 1969018 has 1.78 GiB memory in use. Of the allocated memory 1.55 GiB is allocated by PyTorch, and 37.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meinops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rearrange, einsum\n\u001b[1;32m      2\u001b[0m input_features \u001b[38;5;241m=\u001b[39m rearrange(input_features, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb s f -> (b s) f\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m attribution \u001b[38;5;241m=\u001b[39m \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvirtual_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb f1, f1 f2 -> b f1 f2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/einops/einops.py:907\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*tensors_and_pattern)\u001b[0m\n\u001b[1;32m    905\u001b[0m tensors \u001b[38;5;241m=\u001b[39m tensors_and_pattern[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    906\u001b[0m pattern \u001b[38;5;241m=\u001b[39m _compactify_pattern_for_einsum(pattern)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/einops/_backends.py:287\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, pattern, *x)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;28mself\u001b[39m, pattern, \u001b[38;5;241m*\u001b[39mx):\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/functional.py:386\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    388\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1160.81 GiB. GPU 0 has a total capacity of 15.73 GiB of which 13.95 GiB is free. Process 1969018 has 1.78 GiB memory in use. Of the allocated memory 1.55 GiB is allocated by PyTorch, and 37.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, einsum\n",
    "input_features = rearrange(input_features, 'b s f -> (b s) f')\n",
    "attribution = einsum(input_features, virtual_weights, \"b f1, f1 f2 -> b f1 f2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attribution \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvirtual_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# RuntimeError: self must be a matrix\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# attribution = input_features * virtual_weights\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "source": [
    "attribution = torch.dot(input_features, virtual_weights)\n",
    "# RuntimeError: self must be a matrix\n",
    "# attribution = input_features * virtual_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8256, 6144]), torch.Size([6144, 6143]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.shape, virtual_weights.shape\n",
    "attribution = torch.einsum('bi,ij->bij', input_features, virtual_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution = rearrange(attribution, 'b s f -> (b s) f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 129, 6143])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_indices = rearrange(output_indices, 'b s f -> (b s) f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 30])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_indices[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    attribution = input_features @ virtual_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 129, 6144]), torch.Size([6144, 6143]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.shape, virtual_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to calculate attribution = act*gradient\n",
    "\n",
    "# I believe this is equivalent to the weights of the activations (ignore biases)\n",
    "# It'd be good to actually verify this is the case\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    tr_dec = transcoder.decoder.weight\n",
    "    #TODO: we removed the last weight to help w/ knowing .T and shape. \n",
    "    final_enc = sae_final.encoder.weight[:-1]\n",
    "    virtual_weights = tr_dec.T @ final_enc.T\n",
    "\n",
    "    act_res_mid = act_res_mid.to(device)\n",
    "    input_features, input_acts, input_indices = transcoder.encode(act_res_mid, return_topk=True)\n",
    "    mlp_out_hat = transcoder.decoder(input_features)\n",
    "\n",
    "    output_features, output_acts, output_indices = sae_final.encode(mlp_out_hat + act_res_mid, return_topk=True)\n",
    "\n",
    "    # For efficient gradient calculation, we can get the nonzero_indices of both input & output feature\n",
    "\n",
    "    # W_input = transcoder.decoder.weight[input_indices]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([768, 6144]), torch.Size([64, 129, 30]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcoder.decoder.weight.shape, input_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode(self, x: torch.Tensor, return_topk: bool = False):\n",
    "#     post_relu_feat_acts_BF = nn.functional.relu(self.encoder(x - self.b_dec))\n",
    "#     post_topk = post_relu_feat_acts_BF.topk(self.k, sorted=False, dim=-1)\n",
    "\n",
    "#     # We can't split immediately due to nnsight\n",
    "#     tops_acts_BK = post_topk.values\n",
    "#     top_indices_BK = post_topk.indices\n",
    "\n",
    "#     buffer_BF = torch.zeros_like(post_relu_feat_acts_BF)\n",
    "#     encoded_acts_BF = buffer_BF.scatter_(dim=-1, index=top_indices_BK, src=tops_acts_BK)\n",
    "\n",
    "#     if return_topk:\n",
    "#         return encoded_acts_BF, tops_acts_BK, top_indices_BK\n",
    "#     else:\n",
    "#         return encoded_acts_BF\n",
    "\n",
    "# def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#     return self.decoder(x) + self.b_dec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
