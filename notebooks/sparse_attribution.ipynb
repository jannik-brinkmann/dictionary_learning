{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/circuits/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/dictionary_learning/circuits/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from notebook_utils import load_tinymodel, load_tinydataset, load_saes\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 543.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to tokenize 0 tokens\n",
      "Number of datapoints w/ 129 tokens: 9473\n",
      "Total Tokens: 1.222017M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/notebooks/notebook_utils.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "llm = load_tinymodel()\n",
    "dataset = load_tinydataset(batch_size=1, max_seq_length=128, num_datapoints=10000, to_dataloader=False)\n",
    "all_saes = load_saes(k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient but only on each batch, no accumulation\n",
    "Accumulating gradients over batches != gradient over a large batch\n",
    "We also can't backpropogate through the computation graph over the accumulated normalized sum because the computation graph doesn't exist, lol. \n",
    "\n",
    "There still might be a way to calculate gradient correctly (w/ a custom grad-function), but I'm intentionally making that out of scope.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:15,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 129 | Entropy: 2.9938015937805176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:05<00:23,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 6579 | Entropy: 4.113683223724365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:12<00:32,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 13029 | Entropy: 4.339517593383789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:20<00:36,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 19479 | Entropy: 4.4546613693237305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:30<00:37,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 25929 | Entropy: 4.523906707763672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:42<00:35,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 32379 | Entropy: 4.573797702789307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:54<00:30, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 38829 | Entropy: 4.61957311630249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:09<00:23, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 45279 | Entropy: 4.641940116882324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:26<00:13, 13.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 51729 | Entropy: 4.663559436798096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:45<00:00, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 58179 | Entropy: 4.681214809417725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, einsum\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "target_sae_names = ['torso_1_mlp_out_transcoder', 'torso_1_res_final']\n",
    "saes = [all_saes[name].to(device) for name in target_sae_names]\n",
    "num_input_features = saes[0].encoder.weight.shape[0]\n",
    "num_output_features = saes[1].encoder.weight.shape[0]\n",
    "\n",
    "\n",
    "resid_mid = llm.torso[1].res_mlp\n",
    "resid_final = llm.torso[1].res_final\n",
    "mlp_out = llm.torso[1].mlp\n",
    "\n",
    "entropy_across_batches = []\n",
    "transcoder = saes[0].to(device)\n",
    "sae_final = saes[1].to(device)\n",
    "\n",
    "tr_dec = transcoder.decoder.weight\n",
    "final_enc = sae_final.encoder.weight\n",
    "optimizer = torch.optim.Adam(list(transcoder.parameters()) + list(sae_final.parameters()), lr=1e-3)\n",
    "grads_t_dec = []\n",
    "grads_t_enc = []\n",
    "grads_f_enc = []\n",
    "current_dataset = None\n",
    "for batch_size in tqdm(range(0, 500, 50)):\n",
    "    optimizer.zero_grad()\n",
    "    loader = DataLoader(dataset, batch_size=batch_size+1, shuffle=True)\n",
    "    batch_dict = next(iter(loader))\n",
    "    batch = torch.stack(batch_dict[\"input_ids\"], dim=-1)\n",
    "    batch = batch.to(device)\n",
    "\n",
    "\n",
    "    with torch.no_grad(), llm.trace(batch) as tracr:\n",
    "        act_res_mid = resid_mid.output.save()\n",
    "        act_res_final = resid_final.output.save()\n",
    "        act_mlp_out = mlp_out.output.save()\n",
    "\n",
    "    # Get the input & output activations and indices\n",
    "    act_res_mid = act_res_mid.detach().to(device)\n",
    "    act_res_mid = rearrange(act_res_mid, 'b s d_model -> (b s) d_model')\n",
    "\n",
    "        # Forward pass through SAEs\n",
    "    with torch.set_grad_enabled(True):\n",
    "        feature_by_feature_attribution = torch.zeros(num_input_features, num_output_features).to(device)\n",
    "        running_total_for_each_feature = torch.zeros(num_output_features).to(device)\n",
    "        virtual_weights = transcoder.decoder.weight.T @ sae_final.encoder.weight.T\n",
    "\n",
    "        input_features, input_acts, input_indices = transcoder.encode(act_res_mid, return_topk=True)\n",
    "    \n",
    "        mlp_out_hat = transcoder.decoder(input_features)\n",
    "\n",
    "        output_features, output_acts, output_indices = sae_final.encode(mlp_out_hat + act_res_mid, return_topk=True)\n",
    "        \n",
    "        # Compute attribution for each input-output pair\n",
    "        in_idx = input_indices[:, :, None]    # Shape: [batch, k, 1]\n",
    "        out_idx = output_indices[:, None, :]  # Shape: [batch, 1, k]\n",
    "        result = virtual_weights[in_idx, out_idx]  # Shape: [batch, k, k]\n",
    "        attribution = einsum(input_acts, result,'b k_inp, b k_inp k_out-> b k_inp k_out')\n",
    "\n",
    "        # Initialize full feature matrix\n",
    "        full_attribution = torch.zeros(virtual_weights.shape, device=attribution.device)\n",
    "\n",
    "        # Accumulate attributions for each input-output pair\n",
    "        full_attribution.index_put_(\n",
    "            (in_idx.expand(-1, -1, attribution.shape[-1]).reshape(-1),\n",
    "            out_idx.expand(-1, attribution.shape[1], -1).reshape(-1)),\n",
    "            attribution.reshape(-1),\n",
    "            accumulate=True\n",
    "        )\n",
    "        # Count occurrences of each output index\n",
    "        counts = torch.zeros(virtual_weights.shape[1], device=output_indices.device)\n",
    "        counts.index_add_(0, output_indices.reshape(-1), \n",
    "                        torch.ones_like(output_indices.reshape(-1), dtype=torch.float))\n",
    "        pre_clamp_counts = counts.clone()\n",
    "\n",
    "        # Avoid divide by zero \n",
    "        counts = counts.clamp(min=1)\n",
    "\n",
    "        # Divide output_features by how many times they appear\n",
    "        full_attribution = full_attribution / counts[None, :]\n",
    "\n",
    "        EPS = 1e-10\n",
    "        # Let's only calculate loss over non-zero output features\n",
    "        alive_output_features = pre_clamp_counts != 0\n",
    "        pos_avg =  full_attribution[:, alive_output_features].abs()\n",
    "        normed = pos_avg / (pos_avg.sum(dim=0, keepdim=True))\n",
    "        # Add small epsilon just to logs, maintains sum-to-1 property\n",
    "        logged = torch.log(torch.clamp(normed, min=EPS))\n",
    "        entropy_loss = -(normed * logged).sum(dim=0).mean()\n",
    "\n",
    "        entropy_loss.backward()\n",
    "        print(f\"num tokens: {batch.shape[0]*batch.shape[1]} | Entropy: {entropy_loss.item()}\")\n",
    "        # print(f\"\")\n",
    "        \n",
    "        # Store gradients\n",
    "        grads_t_dec.append(transcoder.decoder.weight.grad.clone().cpu())\n",
    "        grads_t_enc.append(transcoder.encoder.weight.grad.clone().cpu())\n",
    "        grads_f_enc.append(sae_final.encoder.weight.grad.clone().cpu())\n",
    "        \n",
    "        # Optional: check for NaNs\n",
    "        if any(torch.isnan(grad).any() for grad in [grads_t_dec[-1], grads_t_enc[-1], grads_f_enc[-1]]):\n",
    "            print(\"NaN detected in gradients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  2.00it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare the L2 MSE error between the gradients in an imshow matrix image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def gradient_similarity(g1, g2):\n",
    "    # g1, g2 are rectangular matrices of same shape\n",
    "    # Flatten matrices into 1D vectors\n",
    "    g1_flat = g1.reshape(-1)  # or g1.flatten()\n",
    "    g2_flat = g2.reshape(-1)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = (g1_flat @ g2_flat) / (np.linalg.norm(g1_flat) * np.linalg.norm(g2_flat))\n",
    "    return similarity\n",
    "setting = \"t_dec\"\n",
    "# setting = \"t_enc\"\n",
    "# setting = \"f_enc\"\n",
    "if setting == \"t_dec\":\n",
    "    target_grads = torch.stack(grads_t_dec)\n",
    "    title = \"Transcoder Decoder\"\n",
    "elif setting == \"t_enc\":\n",
    "    target_grads = torch.stack(grads_t_enc)\n",
    "    title = \"Transcoder Encoder\"\n",
    "elif setting == \"f_enc\":\n",
    "    target_grads = torch.stack(grads_f_enc)\n",
    "    title = \"Final Encoder\"\n",
    "\n",
    "# Calculate the L2 MSE error between the gradients\n",
    "l2_mse_error = torch.zeros(target_grads.shape[0], target_grads.shape[0])\n",
    "for i in tqdm(range(target_grads.shape[0])):\n",
    "    for j in range(target_grads.shape[0]):\n",
    "        # l2_mse_error[i, j] = torch.nn.functional.mse_loss(target_grads[i], target_grads[j])\n",
    "        l2_mse_error[i, j] = gradient_similarity(target_grads[i], target_grads[j])\n",
    "\n",
    "plt.imshow(l2_mse_error)\n",
    "plt.title(\"Cos Sim of Grads: \"+title)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just calculate Entropy TODO: unfinished. Need to make more efficient like above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_saes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# def update_running_average_with_sum(current_avg, new_sum, current_count, new_count):\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     \"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     Update the running average with a new sum and count.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     updated_avg = updated_sum / total_count\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     return updated_avg, total_count\u001b[39;00m\n\u001b[1;32m     21\u001b[0m target_sae_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorso_1_mlp_out_transcoder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorso_1_res_final\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m saes \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mall_saes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_sae_names\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m num_input_features \u001b[38;5;241m=\u001b[39m saes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m num_output_features \u001b[38;5;241m=\u001b[39m saes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# def update_running_average_with_sum(current_avg, new_sum, current_count, new_count):\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     \"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     Update the running average with a new sum and count.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     updated_avg = updated_sum / total_count\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     return updated_avg, total_count\u001b[39;00m\n\u001b[1;32m     21\u001b[0m target_sae_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorso_1_mlp_out_transcoder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorso_1_res_final\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m saes \u001b[38;5;241m=\u001b[39m [\u001b[43mall_saes\u001b[49m[name]\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m target_sae_names]\n\u001b[1;32m     23\u001b[0m num_input_features \u001b[38;5;241m=\u001b[39m saes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m num_output_features \u001b[38;5;241m=\u001b[39m saes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_saes' is not defined"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, einsum\n",
    "from tqdm import tqdm\n",
    "\n",
    "# def update_running_average_with_sum(current_avg, new_sum, current_count, new_count):\n",
    "#     \"\"\"\n",
    "#     Update the running average with a new sum and count.\n",
    "    \n",
    "#     :param current_avg: Current running average\n",
    "#     :param new_sum: Sum of new values to include in the average\n",
    "#     :param current_count: Number of values in the current average\n",
    "#     :param new_count: Number of new values\n",
    "#     :return: New running average, Updated total count\n",
    "#     \"\"\"\n",
    "#     if current_count == 0:\n",
    "#         return new_sum / new_count, new_count\n",
    "    \n",
    "#     total_count = current_count + new_count\n",
    "#     updated_sum = current_avg * current_count + new_sum\n",
    "#     updated_avg = updated_sum / total_count\n",
    "#     return updated_avg, total_count\n",
    "target_sae_names = ['torso_1_mlp_out_transcoder', 'torso_1_res_final']\n",
    "saes = [all_saes[name].to(device) for name in target_sae_names]\n",
    "num_input_features = saes[0].encoder.weight.shape[0]\n",
    "num_output_features = saes[1].encoder.weight.shape[0]\n",
    "feature_by_feature_attribution = torch.zeros(num_input_features, num_output_features).to(device)\n",
    "running_total_for_each_feature = torch.zeros(num_output_features).to(device)\n",
    "\n",
    "resid_mid = llm.torso[1].res_mlp\n",
    "resid_final = llm.torso[1].res_final\n",
    "mlp_out = llm.torso[1].mlp\n",
    "# for batch_ind, batch in enumerate(dataset):\n",
    "# add tqdm to enumerate correctly\n",
    "#\n",
    "entropy_across_batches = []\n",
    "# Now we want to run through the saes\n",
    "transcoder = saes[0].to(device)\n",
    "sae_final = saes[1].to(device)\n",
    "\n",
    "# Virtual weights = upstream_decoder @ downstream_encoder [feature, feature]\n",
    "tr_dec = transcoder.decoder.weight\n",
    "final_enc = sae_final.encoder.weight\n",
    "virtual_weights = tr_dec.T @ final_enc.T\n",
    "# Set an optimizer on both dec and enc\n",
    "grads_t_dec = []\n",
    "grads_t_enc = []\n",
    "grads_f_enc = []\n",
    "check_grads_every_N = 1\n",
    "with torch.no_grad():\n",
    "    for batch_ind, batch in enumerate(tqdm(dataset)):\n",
    "    \n",
    "\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad(), llm.trace(batch) as tracr:\n",
    "            act_res_mid = resid_mid.output.save()\n",
    "            act_res_final = resid_final.output.save()\n",
    "            act_mlp_out = mlp_out.output.save()\n",
    "\n",
    "        # Get the input & output activations and indices\n",
    "        act_res_mid = act_res_mid.to(device)\n",
    "        act_res_mid = rearrange(act_res_mid, 'b s d_model -> (b s) d_model')\n",
    "        input_features, input_acts, input_indices = transcoder.encode(act_res_mid, return_topk=True)\n",
    "        mlp_out_hat = transcoder.decoder(input_features)\n",
    "\n",
    "        output_features, output_acts, output_indices = sae_final.encode(mlp_out_hat + act_res_mid, return_topk=True)\n",
    "        \n",
    "        new_f_by_f = torch.zeros_like(feature_by_feature_attribution)\n",
    "        for current_output_feature in range(num_output_features):\n",
    "            # Get the batch indices where the output feature is non-zero\n",
    "            # output_indices is [batch, k], so find where k is the current output feature\n",
    "            # sum over feature/k dim, which is at most 1, since a feature can only be activated once/datapoint\n",
    "            nz_batch_indices = (output_indices==current_output_feature).sum(-1).nonzero()[:, 0]\n",
    "            current_output_virtual_weights = virtual_weights[:, current_output_feature]\n",
    "\n",
    "            # TODO: concern that I'm not adding nz_input_ind into the right slots (it's [batch, k] w/ different values for k which define different index)\n",
    "            # Index into the virtual weights & input indices ie find the inputs that activated the output feature\n",
    "            nz_input_ind = input_indices[nz_batch_indices]\n",
    "            batched_virtual_weights = current_output_virtual_weights[nz_input_ind].to(device)\n",
    "            nz_input_acts = input_acts[nz_batch_indices]\n",
    "\n",
    "            # Calculate the attribution ie act*gradient\n",
    "            current_output_attribution = nz_input_acts * batched_virtual_weights \n",
    "\n",
    "            # The new count is the number of non-zero batch indices for this feature\n",
    "            # We need this to update the average; whether or not the current output feature activates on 1 datapoint or\n",
    "            # 100 datapoints in this batch will affect the avg.\n",
    "            new_count = len(nz_batch_indices)\n",
    "\n",
    "            # Update the total attribution, we'll divide by the total count later\n",
    "            # Do scatter add to account for duplicated indices (commented out code just gets last value, not summed)\n",
    "            feature_by_feature_attribution[:, current_output_feature].scatter_add_(\n",
    "                0, \n",
    "                nz_input_ind.flatten(),\n",
    "                current_output_attribution.flatten(),\n",
    "            )\n",
    "            # feature_by_feature_attribution[nz_input_ind, current_output_feature] += current_output_attribution\n",
    "            running_total_for_each_feature[current_output_feature] += new_count\n",
    "        if(batch_ind % check_grads_every_N == 0):\n",
    "            # Now we want to divide feature_by_feature_attribution by each of the times it activated\n",
    "            alive_output_features = running_total_for_each_feature != 0\n",
    "\n",
    "            averaged_feature_by_feature_attribution = feature_by_feature_attribution[:, alive_output_features] / running_total_for_each_feature[None, alive_output_features]\n",
    "            # Now we want to convert to a prob-dist and calculate entropy on it, ignoring dead features\n",
    "            normed_feature_by_feature_attribution = averaged_feature_by_feature_attribution / averaged_feature_by_feature_attribution.abs().sum(dim=0)\n",
    "\n",
    "            logged = normed_feature_by_feature_attribution.abs().log()\n",
    "            logged[logged.isinf()] = 0\n",
    "            entropy = -(normed_feature_by_feature_attribution.abs() * logged).sum(dim=0)\n",
    "            entropy_loss = entropy.mean()\n",
    "            entropy_across_batches.append(entropy_loss.item())\n",
    "            print(f\"Entropy: {entropy_loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Sparse Attribution but w/ Gradients\n",
    "We need to make it differentiable (ie abs to smooth abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/297 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 3.929481029510498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/297 [00:31<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, 0.],\n",
      "        [nan, nan, nan,  ..., nan, nan, 0.],\n",
      "        [nan, nan, nan,  ..., nan, nan, 0.],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, 0.],\n",
      "        [nan, nan, nan,  ..., nan, nan, 0.],\n",
      "        [nan, nan, nan,  ..., nan, nan, 0.]], device='cuda:0')\n",
      "enc\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "f_enc\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, einsum\n",
    "from tqdm import tqdm\n",
    "\n",
    "# def update_running_average_with_sum(current_avg, new_sum, current_count, new_count):\n",
    "#     \"\"\"\n",
    "#     Update the running average with a new sum and count.\n",
    "    \n",
    "#     :param current_avg: Current running average\n",
    "#     :param new_sum: Sum of new values to include in the average\n",
    "#     :param current_count: Number of values in the current average\n",
    "#     :param new_count: Number of new values\n",
    "#     :return: New running average, Updated total count\n",
    "#     \"\"\"\n",
    "#     if current_count == 0:\n",
    "#         return new_sum / new_count, new_count\n",
    "    \n",
    "#     total_count = current_count + new_count\n",
    "#     updated_sum = current_avg * current_count + new_sum\n",
    "#     updated_avg = updated_sum / total_count\n",
    "#     return updated_avg, total_count\n",
    "def smooth_abs(x, epsilon=1e-8):\n",
    "    # add a zero clamp\n",
    "    smoothed = torch.sqrt(x**2 )\n",
    "    return torch.clamp(smoothed, min=0)\n",
    "target_sae_names = ['torso_1_mlp_out_transcoder', 'torso_1_res_final']\n",
    "saes = [all_saes[name].to(device) for name in target_sae_names]\n",
    "num_input_features = saes[0].encoder.weight.shape[0]\n",
    "num_output_features = saes[1].encoder.weight.shape[0]\n",
    "feature_by_feature_attribution = torch.zeros(num_input_features, num_output_features).to(device)\n",
    "running_total_for_each_feature = torch.zeros(num_output_features).to(device)\n",
    "\n",
    "resid_mid = llm.torso[1].res_mlp\n",
    "resid_final = llm.torso[1].res_final\n",
    "mlp_out = llm.torso[1].mlp\n",
    "# for batch_ind, batch in enumerate(dataset):\n",
    "# add tqdm to enumerate correctly\n",
    "#\n",
    "entropy_across_batches = []\n",
    "# Now we want to run through the saes\n",
    "transcoder = saes[0].to(device)\n",
    "sae_final = saes[1].to(device)\n",
    "\n",
    "# Virtual weights = upstream_decoder @ downstream_encoder [feature, feature]\n",
    "tr_dec = transcoder.decoder.weight\n",
    "final_enc = sae_final.encoder.weight\n",
    "virtual_weights = tr_dec.T @ final_enc.T\n",
    "# Set an optimizer on both dec and enc\n",
    "optimizer = torch.optim.Adam([transcoder.decoder.weight, transcoder.encoder.weight, sae_final.encoder.weight], lr=1e-3)\n",
    "grads_t_dec = []\n",
    "grads_t_enc = []\n",
    "grads_f_enc = []\n",
    "# check_grads_every_N = 10\n",
    "check_grads_every_N = 1\n",
    "for batch_ind, batch in enumerate(tqdm(dataset)):\n",
    "    # if check_grads_every_N, then do with torch.no_grad()\n",
    "    # else, do with torch.enable_grad()\n",
    "    compute_grads = (batch_ind % check_grads_every_N == 0)\n",
    "    \n",
    "    # Use a single with statement\n",
    "    with torch.set_grad_enabled(compute_grads):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad(), llm.trace(batch) as tracr:\n",
    "            act_res_mid = resid_mid.output.save()\n",
    "            act_res_final = resid_final.output.save()\n",
    "            act_mlp_out = mlp_out.output.save()\n",
    "\n",
    "        # Get the input & output activations and indices\n",
    "        act_res_mid = act_res_mid.to(device)\n",
    "        act_res_mid = rearrange(act_res_mid, 'b s d_model -> (b s) d_model')\n",
    "        input_features, input_acts, input_indices = transcoder.encode(act_res_mid, return_topk=True)\n",
    "        mlp_out_hat = transcoder.decoder(input_features)\n",
    "\n",
    "        output_features, output_acts, output_indices = sae_final.encode(mlp_out_hat + act_res_mid, return_topk=True)\n",
    "        \n",
    "        new_f_by_f = torch.zeros_like(feature_by_feature_attribution)\n",
    "        for current_output_feature in range(num_output_features):\n",
    "            # Get the batch indices where the output feature is non-zero\n",
    "            # output_indices is [batch, k], so find where k is the current output feature\n",
    "            # sum over feature/k dim, which is at most 1, since a feature can only be activated once/datapoint\n",
    "            nz_batch_indices = (output_indices==current_output_feature).sum(-1).nonzero()[:, 0]\n",
    "            current_output_virtual_weights = virtual_weights[:, current_output_feature]\n",
    "\n",
    "            # TODO: concern that I'm not adding nz_input_ind into the right slots (it's [batch, k] w/ different values for k which define different index)\n",
    "            # Index into the virtual weights & input indices ie find the inputs that activated the output feature\n",
    "            nz_input_ind = input_indices[nz_batch_indices]\n",
    "            batched_virtual_weights = current_output_virtual_weights[nz_input_ind].to(device)\n",
    "            nz_input_acts = input_acts[nz_batch_indices]\n",
    "\n",
    "            # Calculate the attribution ie act*gradient\n",
    "            current_output_attribution = nz_input_acts * batched_virtual_weights \n",
    "\n",
    "            # The new count is the number of non-zero batch indices for this feature\n",
    "            # We need this to update the average; whether or not the current output feature activates on 1 datapoint or\n",
    "            # 100 datapoints in this batch will affect the avg.\n",
    "            new_count = len(nz_batch_indices)\n",
    "\n",
    "            # Update the total attribution, we'll divide by the total count later\n",
    "            # Do scatter add to account for duplicated indices (commented out code just gets last value, not summed)\n",
    "            feature_by_feature_attribution[:, current_output_feature].scatter_add_(\n",
    "                0, \n",
    "                nz_input_ind.flatten(),\n",
    "                current_output_attribution.flatten(),\n",
    "            )\n",
    "            # feature_by_feature_attribution[nz_input_ind, current_output_feature] += current_output_attribution\n",
    "            running_total_for_each_feature[current_output_feature] += new_count\n",
    "        if(batch_ind % check_grads_every_N == 0):\n",
    "            # Now we want to divide feature_by_feature_attribution by each of the times it activated\n",
    "            alive_output_features = running_total_for_each_feature != 0\n",
    "\n",
    "            averaged_feature_by_feature_attribution = feature_by_feature_attribution[:, alive_output_features] / running_total_for_each_feature[None, alive_output_features]\n",
    "            # Now we want to convert to a prob-dist and calculate entropy on it, ignoring dead features\n",
    "            not_smooth_normed_feature_by_feature_attribution = averaged_feature_by_feature_attribution / averaged_feature_by_feature_attribution.abs().sum(dim=0)\n",
    "            normed_feature_by_feature_attribution = averaged_feature_by_feature_attribution / smooth_abs(averaged_feature_by_feature_attribution).sum(dim=0)\n",
    "            \n",
    "            # normed_feature_by_feature_attribution = torch.nn.functional.softmax(averaged_feature_by_feature_attribution, dim=0)\n",
    "\n",
    "\n",
    "            logged = smooth_abs(normed_feature_by_feature_attribution).log()\n",
    "            not_smooth__logged = not_smooth_normed_feature_by_feature_attribution.abs().log()\n",
    "            logged[logged.isinf()] = 0\n",
    "            not_smooth__logged[not_smooth__logged.isinf()] = 0\n",
    "            entropy = -(smooth_abs(normed_feature_by_feature_attribution) * logged).sum(dim=0)\n",
    "            not_smooth_entropy = -(not_smooth_normed_feature_by_feature_attribution.abs() * not_smooth__logged).sum(dim=0)\n",
    "            # entropy = -(normed_feature_by_feature_attribution.abs() * logged).sum(dim=0)\n",
    "            entropy_loss = entropy.mean()\n",
    "            entropy_across_batches.append(entropy_loss.item())\n",
    "            print(f\"Entropy: {entropy_loss.item()}\")\n",
    "\n",
    "        #     # Get the gradient of the entropy loss\n",
    "            entropy_loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_([transcoder.decoder.weight, transcoder.encoder.weight, sae_final.encoder.weight], max_norm=1.0)\n",
    "\n",
    "            # get the gradients\n",
    "            grad_t_dec = transcoder.decoder.weight.grad\n",
    "            grad_t_enc = transcoder.encoder.weight.grad\n",
    "            grad_f_enc = sae_final.encoder.weight.grad\n",
    "            grads_t_dec.append(grad_t_dec.cpu())\n",
    "            grads_t_enc.append(grad_t_enc.cpu())\n",
    "            grads_f_enc.append(grad_f_enc.cpu())\n",
    "            print(\"dec\")\n",
    "            print(grad_t_dec)\n",
    "            print(\"enc\")\n",
    "            print(grad_t_enc)\n",
    "            print(\"f_enc\")\n",
    "            print(grad_f_enc)\n",
    "        break\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: tensor([1., 0., 0., 0.])\n",
      "tensor([1., 0., 0., 0.])\n",
      "tensor([  0.0000, -23.0259, -23.0259, -23.0259])\n",
      "  Squared Error Entropy: 1.0000\n",
      "  Tanh Entropy: 0.2100\n",
      "  Cauchy Entropy: 0.6931\n",
      "  Softplus Entropy: 3.3927\n",
      "  Gaussian Entropy: -3.6065\n",
      "  sqrt_entropy: -0.0000\n",
      "  Sparsity Inducing Loss: 0.0000\n",
      "\n",
      "Distribution: tensor([-1.,  0.,  0.,  0.])\n",
      "tensor([1., 0., 0., 0.])\n",
      "tensor([  0.0000, -23.0259, -23.0259, -23.0259])\n",
      "  Squared Error Entropy: 1.0000\n",
      "  Tanh Entropy: 0.2100\n",
      "  Cauchy Entropy: 0.6931\n",
      "  Softplus Entropy: 2.3927\n",
      "  Gaussian Entropy: -3.6065\n",
      "  sqrt_entropy: -0.0000\n",
      "  Sparsity Inducing Loss: 0.0000\n",
      "\n",
      "Distribution: tensor([0.9900, 0.0100, 0.0000, 0.0000])\n",
      "tensor([0.9900, 0.0100, 0.0000, 0.0000])\n",
      "tensor([-1.0050e-02, -4.6052e+00, -2.3026e+01, -2.3026e+01])\n",
      "  Squared Error Entropy: 1.0000\n",
      "  Tanh Entropy: 0.2100\n",
      "  Cauchy Entropy: 0.6932\n",
      "  Softplus Entropy: 3.3977\n",
      "  Gaussian Entropy: -3.6065\n",
      "  sqrt_entropy: 0.0560\n",
      "  Sparsity Inducing Loss: 0.0101\n",
      "\n",
      "Distribution: tensor([ 0.5000, -0.5000,  0.0000,  0.0000])\n",
      "tensor([0.5000, 0.5000, 0.0000, 0.0000])\n",
      "tensor([ -0.6931,  -0.6931, -23.0259, -23.0259])\n",
      "  Squared Error Entropy: 1.0000\n",
      "  Tanh Entropy: 0.1293\n",
      "  Cauchy Entropy: 0.8109\n",
      "  Softplus Entropy: 2.8951\n",
      "  Gaussian Entropy: -3.5576\n",
      "  sqrt_entropy: 0.6931\n",
      "  Sparsity Inducing Loss: 0.6932\n",
      "\n",
      "Distribution: tensor([ 0.5000, -0.3000,  0.1000, -0.1000])\n",
      "tensor([0.5000, 0.3000, 0.1000, 0.1000])\n",
      "tensor([-0.6931, -1.2040, -2.3026, -2.3026])\n",
      "  Squared Error Entropy: 1.0000\n",
      "  Tanh Entropy: 0.1332\n",
      "  Cauchy Entropy: 0.8053\n",
      "  Softplus Entropy: 3.0615\n",
      "  Gaussian Entropy: -3.5616\n",
      "  sqrt_entropy: 1.1683\n",
      "  Sparsity Inducing Loss: 0.6931\n",
      "\n",
      "Distribution: tensor([ 0.5000, -0.1667,  0.1667, -0.1667])\n",
      "tensor([0.5000, 0.1667, 0.1667, 0.1667])\n",
      "tensor([-0.6932, -1.7917, -1.7917, -1.7917])\n",
      "  Squared Error Entropy: 1.0000\n",
      "  Tanh Entropy: 0.1371\n",
      "  Cauchy Entropy: 0.7997\n",
      "  Softplus Entropy: 3.1834\n",
      "  Gaussian Entropy: -3.5649\n",
      "  sqrt_entropy: 1.2425\n",
      "  Sparsity Inducing Loss: 0.6932\n",
      "\n",
      "Distribution: tensor([0.2500, 0.2500, 0.2500, 0.2500])\n",
      "tensor([0.2500, 0.2500, 0.2500, 0.2500])\n",
      "tensor([-1.3863, -1.3863, -1.3863, -1.3863])\n",
      "  Squared Error Entropy: 1.0000\n",
      "  Tanh Entropy: 0.0729\n",
      "  Cauchy Entropy: 0.8926\n",
      "  Softplus Entropy: 3.8963\n",
      "  Gaussian Entropy: -3.5300\n",
      "  sqrt_entropy: 1.3863\n",
      "  Sparsity Inducing Loss: 1.3863\n",
      "\n",
      "Distribution: tensor([4., 4., 4., 4.])\n",
      "tensor([0.2500, 0.2500, 0.2500, 0.2500])\n",
      "tensor([-1.3863, -1.3863, -1.3863, -1.3863])\n",
      "  Squared Error Entropy: 1.0000\n",
      "  Tanh Entropy: 0.0729\n",
      "  Cauchy Entropy: 0.8926\n",
      "  Softplus Entropy: 3.8963\n",
      "  Gaussian Entropy: -3.5300\n",
      "  sqrt_entropy: 1.3863\n",
      "  Sparsity Inducing Loss: 1.3863\n",
      "\n",
      "Squared Error Entropy gradients: tensor([-3.5763e-07,  3.5763e-07, -5.9605e-08,  5.9605e-08])\n",
      "Tanh Entropy gradients: tensor([ 0.0156, -0.0156, -0.0778,  0.0778])\n",
      "Cauchy Entropy gradients: tensor([-0.0226,  0.0226,  0.1131, -0.1131])\n",
      "Softplus Entropy gradients: tensor([0.6930, 0.6937, 0.6951, 0.6917])\n",
      "Gaussian Entropy gradients: tensor([-0.0075,  0.0075,  0.0377, -0.0377])\n",
      "tensor([0.4167, 0.4167, 0.0833, 0.0833], grad_fn=<DivBackward0>)\n",
      "tensor([-0.8755, -0.8755, -2.4849, -2.4849], grad_fn=<LogBackward0>)\n",
      "sqrt_entropy gradients: tensor([-0.2235,  0.2235,  1.1177, -1.1177])\n",
      "Sparsity Inducing Loss gradients: tensor([-0.1667,  0.1667,  0.8333, -0.8333])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def squared_error_entropy(x):\n",
    "    normalized = x / torch.sqrt((x**2).sum(dim=0, keepdim=True) + 1e-8)\n",
    "    return (normalized**2).sum(dim=0)\n",
    "\n",
    "def tanh_entropy(x, scale=1.0):\n",
    "    normalized = x / torch.sqrt((x**2).sum(dim=0, keepdim=True) + 1e-8)\n",
    "    return -((torch.tanh(scale * normalized)**2).sum(dim=0) - 1) / 2\n",
    "\n",
    "def cauchy_entropy(x, scale=1.0):\n",
    "    normalized = x / torch.sqrt((x**2).sum(dim=0, keepdim=True) + 1e-8)\n",
    "    return torch.log(1 + scale * normalized**2).sum(dim=0)\n",
    "\n",
    "def softplus_entropy(x, beta=1.0):\n",
    "    normalized = x / torch.sqrt((x**2).sum(dim=0, keepdim=True) + 1e-8)\n",
    "    return F.softplus(beta * normalized, beta=beta).sum(dim=0) / beta\n",
    "\n",
    "def gaussian_entropy(x, sigma=1.0):\n",
    "    normalized = x / torch.sqrt((x**2).sum(dim=0, keepdim=True) + 1e-8)\n",
    "    return -torch.exp(-normalized**2 / (2 * sigma**2)).sum(dim=0)\n",
    "\n",
    "def gaussian_entropy(x, sigma=1.0):\n",
    "    normalized = x / torch.sqrt((x**2).sum(dim=0, keepdim=True) + 1e-8)\n",
    "    return -torch.exp(-normalized**2 / (2 * sigma**2)).sum(dim=0)\n",
    "\n",
    "def smooth_absolute(x):\n",
    "    return torch.sqrt(x**2 + 1e-8)\n",
    "    \n",
    "\n",
    "def sqrt_entropy(x):\n",
    "    pos_x = torch.sqrt(x**2)\n",
    "    normalized = pos_x / (pos_x.sum(dim=0, keepdim=True) + 1e-8)\n",
    "    # normalized = x / x.abs().sum(dim=0, keepdim=True)\n",
    "    # logged = normalized.abs().log()\n",
    "    logged = torch.log(normalized + 1e-10)\n",
    "    print(normalized)\n",
    "    print(logged)\n",
    "    # logged[logged.isinf()] = 0\n",
    "    # return torch.sqrt(normalized.abs()).sum(dim=0)\n",
    "    return -(normalized * logged).sum(dim=0)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ... (keep your other entropy functions)\n",
    "\n",
    "def sparsity_inducing_loss(x):\n",
    "    pos_x = torch.sqrt(x**2 + 1e-10)\n",
    "    # pos_x = torch.sqrt(x**2)\n",
    "    normalized = pos_x / (pos_x.sum(dim=0, keepdim=True) + 1e-10)\n",
    "    # normalized = pos_x / (pos_x.sum(dim=0, keepdim=True))\n",
    "    # return -torch.log(normalized.max() + 1e-10) + torch.sum(normalized) -1\n",
    "    # return -torch.log(normalized.max() + 1e-10)\n",
    "    return -torch.log(normalized.max() + 1e-10)\n",
    "    # return -torch.log(normalized.max()) + torch.sum(normalized) -1\n",
    "\n",
    "def compare_metrics(x):\n",
    "    metrics = {\n",
    "        'Squared Error Entropy': squared_error_entropy(x),\n",
    "        'Tanh Entropy': tanh_entropy(x),\n",
    "        'Cauchy Entropy': cauchy_entropy(x),\n",
    "        'Softplus Entropy': softplus_entropy(x),\n",
    "        'Gaussian Entropy': gaussian_entropy(x),\n",
    "        'sqrt_entropy': sqrt_entropy(x),\n",
    "        'Sparsity Inducing Loss': sparsity_inducing_loss(x),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_distributions = [\n",
    "        # torch.tensor([0.0, 0.0, 0.0, 0.0]),\n",
    "        # torch.tensor([5.0, 0.0, 0.0, 0.0]),\n",
    "        # torch.tensor([5.0, 0.5, 0.0, 0.0]),\n",
    "        # torch.tensor([1.0, 0.1, 0.0, 0.0]),\n",
    "        torch.tensor([1.0, 0.0, 0.0, 0.0]),\n",
    "        torch.tensor([-1.0, 0.0, 0.0, 0.0]),\n",
    "        torch.tensor([0.99, 0.01, 0.0, 0.0]),\n",
    "        torch.tensor([0.5, -0.5, 0.0, 0.0]),\n",
    "        torch.tensor([0.5, -0.3, 0.1, -0.1]),\n",
    "        torch.tensor([0.5, -0.16667, 0.16667, -0.16667]),\n",
    "        torch.tensor([0.25, 0.25, 0.25, 0.25]),\n",
    "        torch.tensor([4.0, 4.0, 4.0, 4.0]),\n",
    "    ]\n",
    "\n",
    "    for dist in test_distributions:\n",
    "        print(f\"Distribution: {dist}\")\n",
    "        for name, value in compare_metrics(dist).items():\n",
    "            print(f\"  {name}: {value.item():.4f}\")\n",
    "        print()\n",
    "\n",
    "    # Gradient check\n",
    "    x = torch.tensor([0.5, -0.5, 0.1, -0.1], requires_grad=True)\n",
    "    for name, func in [\n",
    "        ('Squared Error Entropy', squared_error_entropy),\n",
    "        ('Tanh Entropy', tanh_entropy),\n",
    "        ('Cauchy Entropy', cauchy_entropy),\n",
    "        ('Softplus Entropy', softplus_entropy),\n",
    "        ('Gaussian Entropy', gaussian_entropy),\n",
    "        ('sqrt_entropy', sqrt_entropy),\n",
    "        ('Sparsity Inducing Loss', sparsity_inducing_loss),\n",
    "    ]:\n",
    "        y = func(x)\n",
    "        try:\n",
    "            y.backward()\n",
    "            if torch.isnan(x.grad).any():\n",
    "                print(f\"{name} | NaN in gradients\")\n",
    "            print(f\"{name} gradients: {x.grad}\")\n",
    "            x.grad.zero_()\n",
    "        except Exception as e:\n",
    "            print(f\"{name}: Gradient computation failed - {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5887, device='cuda:0')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6\n",
    "(not_smooth_normed_feature_by_feature_attribution[:, N] == normed_feature_by_feature_attribution[:, N]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nz_ind = not_smooth_normed_feature_by_feature_attribution[:, N].nonzero()\n",
    "not_smooth_normed_feature_by_feature_attribution[nz_ind, N], normed_feature_by_feature_attribution[nz_ind, N]\n",
    "# Plot both, one as x and one as y\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(not_smooth_normed_feature_by_feature_attribution[nz_ind, N].detach().cpu(), normed_feature_by_feature_attribution[nz_ind, N].detach().cpu())\n",
    "# Draw a diagonal thin linear between the min and max of both\n",
    "min_val = not_smooth_normed_feature_by_feature_attribution[nz_ind, N].min().item()\n",
    "max_val = not_smooth_normed_feature_by_feature_attribution[nz_ind, N].max().item()\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red')\n",
    "plt.xlabel(\"Not Smoothed\")\n",
    "plt.ylabel(\"Smoothed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.7974, 1.0676, 2.3563,  ..., 2.2825, 0.9650, 0.0000], device='cuda:0',\n",
       "        grad_fn=<SumBackward1>),\n",
       " torch.Size([6144, 6107]),\n",
       " tensor(1.0000, device='cuda:0', grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed = averaged_feature_by_feature_attribution / averaged_feature_by_feature_attribution.abs().sum(dim=0)\n",
    "normed.abs().sum(dim=1), normed.shape, normed.abs()[:, 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mentropy_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_([transcoder\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mweight, transcoder\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mweight, sae_final\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mweight], max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m      4\u001b[0m transcoder\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/dictionary_learning/circuits/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/circuits/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/circuits/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "entropy_loss.backward()\n",
    "torch.nn.utils.clip_grad_norm_([transcoder.decoder.weight, transcoder.encoder.weight, sae_final.encoder.weight], max_norm=1.0)\n",
    "transcoder.decoder.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9295, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot entropy_across_batches\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(entropy_across_batches)\n",
    "plt.xlabel(\"Number of Tokens\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "# Set x indicies to be in increments of 10 to make it easier to read\n",
    "# Each tick is 128*32 tokens\n",
    "# Measure as M of tokens\n",
    "n_ticks = 50\n",
    "plt.xticks(range(0, len(entropy_across_batches), n_ticks), [f\"{i*128*32/1e6:.2f}M\" for i in range(0, len(entropy_across_batches), n_ticks)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.206844329833984]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_across_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2069, device='cuda:0')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want to divide feature_by_feature_attribution by each of the times it activated\n",
    "alive_output_features = running_total_for_each_feature != 0\n",
    "\n",
    "averaged_feature_by_feature_attribution = feature_by_feature_attribution[:, alive_output_features] / running_total_for_each_feature[alive_output_features].unsqueeze(0)\n",
    "# Now we want to convert to a prob-dist and calculate entropy on it, ignoring dead features\n",
    "normed_feature_by_feature_attribution = averaged_feature_by_feature_attribution / averaged_feature_by_feature_attribution.abs().sum(dim=0)\n",
    "\n",
    "logged = normed_feature_by_feature_attribution.abs().log()\n",
    "logged[logged.isinf()] = 0\n",
    "entropy = -(normed_feature_by_feature_attribution.abs() * logged).sum(dim=0)\n",
    "entropy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:0'),\n",
       " tensor(False, device='cuda:0'),\n",
       " tensor(False, device='cuda:0'),\n",
       " tensor(True, device='cuda:0'),\n",
       " tensor(True, device='cuda:0'),\n",
       " tensor(False, device='cuda:0'),\n",
       " tensor(True, device='cuda:0'))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(running_total_for_each_feature[alive_output_features] == 0).any(), running_total_for_each_feature[alive_output_features].isnan().any(), feature_by_feature_attribution.isnan().any(), normed_feature_by_feature_attribution.isnan().any(), entropy.isnan().any(), averaged_feature_by_feature_attribution.isnan().any(), (averaged_feature_by_feature_attribution == 0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged[logged.isnan()], logged.isnan().nonzero()\n",
    "normed_feature_by_feature_attribution.abs()[0, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    -inf,     -inf,     -inf,  ..., -10.5742,     -inf,     -inf],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in range(10):\n",
    "    assert (normed_feature_by_feature_attribution[:, N] == feature_by_feature_attribution[:, N] / running_total_for_each_feature[N]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False, False,  ..., False, False, False], device='cuda:0'),\n",
       " torch.Size([4128, 30]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_acts[output_indices==0]\n",
    "input_acts[output_indices==0]\n",
    "(output_indices==0).sum(-1) != 0, input_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2369],\n",
       "        [3193],\n",
       "        [3194],\n",
       "        [3204],\n",
       "        [3207],\n",
       "        [3798]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((output_indices==0).sum(-1) != 0).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_output_feature = 0\n",
    "num_input_features = input_features.shape[-1]\n",
    "num_output_features = output_features.shape[-1]\n",
    "feature_by_feature_attribution = torch.zeros(num_input_features, num_output_features).to(device)\n",
    "# features_set_yet = torch.zeros(num_output_features, dtype=torch.bool)\n",
    "iteration = 1\n",
    "\n",
    "for current_output_feature in range(num_output_features):\n",
    "    # Get the batch indices where the output feature is non-zero\n",
    "    nz_batch_indices = (output_indices==current_output_feature).sum(-1).nonzero()[:, 0]\n",
    "    output_virtual_weights = virtual_weights[:, current_output_feature]\n",
    "\n",
    "    # Index into the virtual weights & input indices ie find the inputs that activated the output feature\n",
    "    nz_input_ind = input_indices[nz_batch_indices]\n",
    "    batched_virtual_weights = output_virtual_weights[nz_input_ind].to(device)\n",
    "    nz_input_acts = input_acts[nz_batch_indices]\n",
    "\n",
    "    # Calculate the attribution ie act*gradient\n",
    "    current_output_attribution = nz_input_acts * batched_virtual_weights \n",
    "\n",
    "    # Set the feature by feature attribution (average w/ existing attributions)    \n",
    "    averaged_current_output_attribution = current_output_attribution.mean(dim=0)\n",
    "    tmp_feature_list = torch.zeros(num_input_features).to(device)\n",
    "    # Assign the averaged attributions to the correct input features\n",
    "    # tmp_feature_list[nz_input_ind] = averaged_current_output_attribution\n",
    "\n",
    "    feature_by_feature_attribution[nz_input_ind, current_output_feature] += averaged_current_output_attribution\n",
    "\n",
    "# Normalize the attributions (by abs value cause negative gradients)\n",
    "# total_abs_value = current_output_attribution.abs().sum(dim=-1)\n",
    "# normed_current_output_attribution = current_output_attribution / total_abs_value[:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0'),\n",
       " tensor(0.7414, device='cuda:0'))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution.abs().sum(dim=-1), normed_current_output_attribution.mean(dim=0).abs().sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution.abs().mean(dim=0).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 30])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Normalize: \u001b[39;00m\n\u001b[1;32m      3\u001b[0m normed_current_output_attribution \u001b[38;5;241m=\u001b[39m current_output_attribution \u001b[38;5;241m/\u001b[39m total_abs_value[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m normed_current_output_attribution\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_abs_value = current_output_attribution.abs().sum(dim=-1)\n",
    "# Normalize: \n",
    "normed_current_output_attribution = current_output_attribution / total_abs_value[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6227e-02, -2.6679e-03, -2.5494e-02, -1.2283e-03,  1.7044e-01,\n",
       "         -4.9746e-02, -1.8890e-02, -6.3689e-02, -3.3854e-02,  1.7237e-01,\n",
       "         -6.0978e-03,  2.1763e-02, -4.3416e-02,  7.5457e-02,  2.9024e-02,\n",
       "         -6.1067e-03,  5.2058e-03, -3.8862e-02, -6.2616e-03, -1.0429e-02,\n",
       "         -2.1213e-02, -3.2377e-02, -2.1631e-02,  1.1801e-02, -4.8583e-02,\n",
       "          7.9568e-03,  3.5445e-03, -9.7144e-03, -1.8767e-02, -7.1831e-03],\n",
       "        [-1.3719e-02,  2.5239e-03,  4.5559e-01,  6.0995e-03,  1.5561e-01,\n",
       "         -4.0269e-02, -1.2523e-02, -4.5647e-02,  6.8993e-03, -1.0656e-02,\n",
       "         -5.3215e-02, -1.6520e-02, -9.7398e-03,  2.4028e-03, -1.1964e-02,\n",
       "         -5.8181e-03, -1.9840e-02, -1.1012e-03, -1.8136e-02,  2.4025e-03,\n",
       "          2.2144e-04,  1.3957e-02, -2.2930e-02,  9.7942e-03, -1.6925e-02,\n",
       "         -5.8936e-03, -6.2075e-03,  1.3838e-02, -1.9537e-02,  2.1156e-05],\n",
       "        [-9.3610e-02,  2.0581e-03,  2.8441e-03, -1.7609e-02,  3.2889e-01,\n",
       "          2.9626e-03, -5.8919e-03, -9.6776e-03,  1.6282e-02, -3.5212e-02,\n",
       "         -1.0118e-01,  1.1903e-02,  2.6110e-02, -4.1736e-02,  1.5991e-02,\n",
       "         -3.8399e-03, -5.5625e-03, -3.4391e-02, -4.4615e-02, -2.1330e-02,\n",
       "          2.6017e-03,  2.2486e-04, -3.8361e-02,  4.8169e-02,  3.6406e-02,\n",
       "          1.2068e-02, -1.4367e-02, -1.3132e-02, -2.5259e-03, -1.0446e-02],\n",
       "        [-8.1073e-03,  4.2762e-02, -5.2288e-02,  4.5075e-03,  3.3414e-01,\n",
       "          2.7188e-03, -1.4417e-02, -1.8804e-02,  1.2070e-01,  4.3481e-03,\n",
       "          4.6848e-05, -4.1434e-02, -3.2482e-02, -1.1042e-02, -1.0281e-02,\n",
       "          1.1483e-03, -3.4628e-02,  2.5828e-03, -2.0375e-02,  2.2612e-02,\n",
       "         -4.7735e-03,  3.2990e-04, -2.8831e-02, -3.4438e-02,  1.6669e-04,\n",
       "         -4.7174e-02, -1.0905e-02, -8.9945e-03, -7.7301e-02, -7.6553e-03],\n",
       "        [-5.0751e-03, -4.3663e-02,  3.6039e-03,  2.9102e-01,  6.3041e-03,\n",
       "         -1.4183e-02, -6.8183e-02,  6.1243e-03, -4.5275e-02, -2.7905e-03,\n",
       "         -1.1467e-02, -7.7277e-02,  5.9998e-03,  1.1346e-02,  7.9721e-04,\n",
       "         -3.7884e-02, -1.1661e-02, -2.0265e-02,  1.7895e-02, -5.9277e-02,\n",
       "         -1.9032e-02, -7.0333e-03,  1.2288e-02,  3.3335e-02, -2.6896e-02,\n",
       "         -1.2939e-02, -1.0968e-01,  6.8002e-03, -1.8959e-02, -1.2946e-02],\n",
       "        [ 3.2406e-03,  5.2416e-01, -2.5509e-03, -2.0306e-03, -7.5386e-03,\n",
       "          1.6643e-01,  1.2463e-02,  4.3980e-03, -1.0011e-02,  1.3485e-02,\n",
       "         -2.3036e-03, -1.9625e-03, -1.6080e-02,  8.4582e-04,  9.0141e-03,\n",
       "         -1.5201e-02, -3.6115e-03,  5.4018e-03, -1.2612e-02, -3.4631e-03,\n",
       "         -3.1816e-02, -2.7081e-03, -3.3674e-02,  1.9163e-02,  5.9009e-03,\n",
       "         -1.0380e-02, -6.0363e-02,  3.3278e-03, -1.5466e-02,  4.0239e-04]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2906, 0.4918, 0.3760, 0.3835, 0.3477, 0.5571], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_current_output_attribution.norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4699, device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_output_attribution[0].abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_input_indices = torch.unique(input_indices)\n",
    "input_features[:, unique_input_indices].isnan().any()\n",
    "unique_output_indices = torch.unique(output_indices)\n",
    "\n",
    "# output_features.shape, unique_output_indices.shape\n",
    "# virtual_weights[unique_input_indices][:, unique_output_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6144, 6143]), tensor(6143, device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virtual_weights.shape, unique_output_indices.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 795.99 GiB. GPU 0 has a total capacity of 15.73 GiB of which 14.37 GiB is free. Process 2007258 has 1.35 GiB memory in use. Of the allocated memory 1.07 GiB is allocated by PyTorch, and 93.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m sparse_virtual_weights \u001b[38;5;241m=\u001b[39m virtual_weights[unique_input_indices][:, unique_output_indices]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Perform the sparse matrix multiplication\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m spar_attr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbi,ij->bij\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_input_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_virtual_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# # Create a tensor to hold the full attribution\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# full_attribution = torch.zeros(input_features.shape[0], input_features.shape[1], virtual_weights.shape[1], device=input_features.device)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# # Place the sparse attribution results in the correct positions in the full attribution tensor\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# full_attribution[:, unique_input_indices[:, None], unique_output_indices] = spar_attr\u001b[39;00m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/functional.py:386\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    388\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 795.99 GiB. GPU 0 has a total capacity of 15.73 GiB of which 14.37 GiB is free. Process 2007258 has 1.35 GiB memory in use. Of the allocated memory 1.07 GiB is allocated by PyTorch, and 93.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum\n",
    "\n",
    "\n",
    "def sparse_attribution(input_features, virtual_weights, input_indices, output_indices):\n",
    "    # Find unique input and output indices across the batch\n",
    "    unique_input_indices = torch.unique(input_indices)\n",
    "    unique_output_indices = torch.unique(output_indices)\n",
    "\n",
    "    # combine batch and sequence dimensions\n",
    "    input_features = rearrange(input_features, 'b s i -> (b s) i')\n",
    "\n",
    "    # Extract relevant slices of input_features and virtual_weights\n",
    "    sparse_input_features = input_features[:, unique_input_indices]\n",
    "    sparse_virtual_weights = virtual_weights[unique_input_indices][:, unique_output_indices]\n",
    "\n",
    "    # Perform the sparse matrix multiplication\n",
    "    sparse_attribution = torch.einsum('bi,ij->bij', sparse_input_features, sparse_virtual_weights)\n",
    "\n",
    "    # Create a tensor to hold the full attribution\n",
    "    full_attribution = torch.zeros(input_features.shape[0], input_features.shape[1], virtual_weights.shape[1], device=input_features.device)\n",
    "\n",
    "    # Place the sparse attribution results in the correct positions in the full attribution tensor\n",
    "    full_attribution[:, unique_input_indices[:, None], unique_output_indices] = sparse_attribution\n",
    "\n",
    "    return full_attribution\n",
    "\n",
    "# Usage\n",
    "# Assuming input_features, virtual_weights, input_indices, and output_indices are defined\n",
    "# attribution = sparse_attribution(input_features, virtual_weights, input_indices, output_indices)\n",
    "\n",
    "unique_input_indices = torch.unique(input_indices)\n",
    "unique_output_indices = torch.unique(output_indices)\n",
    "\n",
    "# Extract relevant slices of input_features and virtual_weights\n",
    "sparse_input_features = input_features[:, unique_input_indices]\n",
    "sparse_virtual_weights = virtual_weights[unique_input_indices][:, unique_output_indices]\n",
    "\n",
    "# Perform the sparse matrix multiplication\n",
    "spar_attr = torch.einsum('bi,ij->bij', sparse_input_features, sparse_virtual_weights)\n",
    "\n",
    "# # Create a tensor to hold the full attribution\n",
    "# full_attribution = torch.zeros(input_features.shape[0], input_features.shape[1], virtual_weights.shape[1], device=input_features.device)\n",
    "\n",
    "# # Place the sparse attribution results in the correct positions in the full attribution tensor\n",
    "# full_attribution[:, unique_input_indices[:, None], unique_output_indices] = spar_attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8256, 6144]), torch.Size([4292]), torch.Size([6030]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.shape, unique_input_indices.shape, unique_output_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8256, 4292]), torch.Size([4292, 6030]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_input_features.shape, sparse_virtual_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_features shape: torch.Size([64, 129, 6144])\n",
      "unique_input_indices shape: torch.Size([4292])\n",
      "Max value in unique_input_indices: 6142\n",
      "Min value in unique_input_indices: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"input_features shape:\", input_features.shape)\n",
    "unique_input_indices = torch.unique(input_indices)\n",
    "print(\"unique_input_indices shape:\", unique_input_indices.shape)\n",
    "print(\"Max value in unique_input_indices:\", unique_input_indices.max().item())\n",
    "print(\"Min value in unique_input_indices:\", unique_input_indices.min().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_input_indices = input_indices.unique()\n",
    "unique_output_indices = output_indices.unique()\n",
    "\n",
    "# # Extract relevant slices of input_features and virtual_weights\n",
    "sparse_input_features = input_features[:, unique_input_indices]\n",
    "sparse_virtual_weights = virtual_weights[unique_input_indices][:, unique_output_indices]\n",
    "# sparse_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4292,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq = input_indices.unique().cpu().numpy()\n",
    "uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minput_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "input_features.index([0,1], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 32\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m full_attribution\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Assuming input_features, virtual_weights, input_indices, and output_indices are defined\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# attribution = sparse_attribution(input_features, virtual_weights, input_indices, output_indices)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m unique_input_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m unique_output_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(output_indices)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Extract relevant slices of input_features and virtual_weights\u001b[39;00m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/_jit_internal.py:503\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/_jit_internal.py:503\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/functional.py:997\u001b[0m, in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 997\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/functional.py:911\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    903\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    905\u001b[0m         dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[1;32m    909\u001b[0m     )\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1160.81 GiB. GPU 0 has a total capacity of 15.73 GiB of which 13.95 GiB is free. Process 1969018 has 1.78 GiB memory in use. Of the allocated memory 1.55 GiB is allocated by PyTorch, and 37.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meinops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rearrange, einsum\n\u001b[1;32m      2\u001b[0m input_features \u001b[38;5;241m=\u001b[39m rearrange(input_features, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb s f -> (b s) f\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m attribution \u001b[38;5;241m=\u001b[39m \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvirtual_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb f1, f1 f2 -> b f1 f2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/einops/einops.py:907\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*tensors_and_pattern)\u001b[0m\n\u001b[1;32m    905\u001b[0m tensors \u001b[38;5;241m=\u001b[39m tensors_and_pattern[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    906\u001b[0m pattern \u001b[38;5;241m=\u001b[39m _compactify_pattern_for_einsum(pattern)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/einops/_backends.py:287\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, pattern, *x)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;28mself\u001b[39m, pattern, \u001b[38;5;241m*\u001b[39mx):\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/test_env/lib/python3.11/site-packages/torch/functional.py:386\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    388\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1160.81 GiB. GPU 0 has a total capacity of 15.73 GiB of which 13.95 GiB is free. Process 1969018 has 1.78 GiB memory in use. Of the allocated memory 1.55 GiB is allocated by PyTorch, and 37.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, einsum\n",
    "input_features = rearrange(input_features, 'b s f -> (b s) f')\n",
    "attribution = einsum(input_features, virtual_weights, \"b f1, f1 f2 -> b f1 f2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attribution \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvirtual_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# RuntimeError: self must be a matrix\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# attribution = input_features * virtual_weights\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "source": [
    "attribution = torch.dot(input_features, virtual_weights)\n",
    "# RuntimeError: self must be a matrix\n",
    "# attribution = input_features * virtual_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8256, 6144]), torch.Size([6144, 6143]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.shape, virtual_weights.shape\n",
    "attribution = torch.einsum('bi,ij->bij', input_features, virtual_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution = rearrange(attribution, 'b s f -> (b s) f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 129, 6143])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_indices = rearrange(output_indices, 'b s f -> (b s) f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 30])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_indices[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    attribution = input_features @ virtual_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 129, 6144]), torch.Size([6144, 6143]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.shape, virtual_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to calculate attribution = act*gradient\n",
    "\n",
    "# I believe this is equivalent to the weights of the activations (ignore biases)\n",
    "# It'd be good to actually verify this is the case\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    tr_dec = transcoder.decoder.weight\n",
    "    #TODO: we removed the last weight to help w/ knowing .T and shape. \n",
    "    final_enc = sae_final.encoder.weight[:-1]\n",
    "    virtual_weights = tr_dec.T @ final_enc.T\n",
    "\n",
    "    act_res_mid = act_res_mid.to(device)\n",
    "    input_features, input_acts, input_indices = transcoder.encode(act_res_mid, return_topk=True)\n",
    "    mlp_out_hat = transcoder.decoder(input_features)\n",
    "\n",
    "    output_features, output_acts, output_indices = sae_final.encode(mlp_out_hat + act_res_mid, return_topk=True)\n",
    "\n",
    "    # For efficient gradient calculation, we can get the nonzero_indices of both input & output feature\n",
    "\n",
    "    # W_input = transcoder.decoder.weight[input_indices]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([768, 6144]), torch.Size([64, 129, 30]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcoder.decoder.weight.shape, input_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode(self, x: torch.Tensor, return_topk: bool = False):\n",
    "#     post_relu_feat_acts_BF = nn.functional.relu(self.encoder(x - self.b_dec))\n",
    "#     post_topk = post_relu_feat_acts_BF.topk(self.k, sorted=False, dim=-1)\n",
    "\n",
    "#     # We can't split immediately due to nnsight\n",
    "#     tops_acts_BK = post_topk.values\n",
    "#     top_indices_BK = post_topk.indices\n",
    "\n",
    "#     buffer_BF = torch.zeros_like(post_relu_feat_acts_BF)\n",
    "#     encoded_acts_BF = buffer_BF.scatter_(dim=-1, index=top_indices_BK, src=tops_acts_BK)\n",
    "\n",
    "#     if return_topk:\n",
    "#         return encoded_acts_BF, tops_acts_BK, top_indices_BK\n",
    "#     else:\n",
    "#         return encoded_acts_BF\n",
    "\n",
    "# def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#     return self.decoder(x) + self.b_dec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
